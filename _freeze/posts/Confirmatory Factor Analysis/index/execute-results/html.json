{
  "hash": "a3fcdd023c13a94daa59d8002a359c13",
  "result": {
    "markdown": "---\ntitle: \"Confirmatory Factor Analysis\"\nformat: \n  revealjs:\n    theme: league\n    transition: slide\n    background-transition: zoom\n    slide-number: c/t\n    show-slide-number: all\n    chalkboard: true\n    background-size: cover\n    smaller: true\n    echo: true\n    code-fold: true\n    code-summary: \"Show the code\"\nauthor: \"Dr Lazaros Gonidis\"\ndate: \"2024-02-13\"\nimage: \"image1.jpg\"\n---\n\n\n## Today's Aims\n\nToday we will go through confirmatory factor analysis using lavaan. Our main focus will be lavaan syntax and the interpretation of output for different models and not going through the detailed mathematics behind the **CFA processes.** We will get a chance to talk about the mathematics and more during the next weeks of more intermediate and advanced topics.\n\n## Today's examples\n\nWe will be working on the same variables that we generated last week during the **EFA**. We will go through the process of **one factor CFA** and **two factor CFA**.\n\nWe specifically explored a model with two factors and overall 6 items, today we will first attempt to confirm a model where **three** items load to latent variable A. **This will be our one-factor CFA**.\n\nIn the second part of our workshop we will attempt to confirm a model with two **latent variables A and B**.\n\n## Terminology\n\nToday we will also be referring back to many of the terms that we have defined in the past.\n\n1.  Observed variables\n2.  Latent variables\n3.  Directional/regression paths\n4.  Non-directional paths/covariance/variance\n5.  Model parameters\n6.  Exogenous, endogenous variables\n7.  Measurement and structural model\n\n## We will expand on terminology today\n\n1.  **Scale:** latent variables do not have a measurement scale, instead we have to define one for them. To do that we need to set an **origin** and a **unit**\n    1.  **Origin:** we can set the mean to **0**\n    2.  **Unit**\n        1.  Either set the **variance to 1**\n        2.  Or, use the same unit as that of one of the **measured variables ( only 1 item)**\n\n## Notations in lavaan (refresher)\n\n-   **`~`** **predict**, used for regression of observed outcome to observed predictors\n\n-   **`=~`** **indicator**, used for latent variable to observed indicators\n\n-   **`~~`** **covariance**\n\n-   **`1*`** **fixes** **parameter** or **loading** to **1**\n\n-   **`NA*`** **frees** **parameter** or **loading**\n\n-   **`~1`** **intercept** or mean (e.g., **`x1 ~ 1`** estimates the mean of variable **`x1`**)\n\n-   **`a*`** **defines** the **parameter** 'a',\n\n## Number of parameters (refresher)\n\nAs mentioned before every **path** or (co)**variance** that has not been fixed to a specific value will have to be estimated\n\n1.  Factor loadings\n2.  Factor covariances\n3.  Factor variances\n4.  Error variances\n\n## Last week's example\n\nLast week we generated random data using the 1212 seed. Today we will carry out **CFA** on the same model but using 3131 as a seed.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(3131)\n### normally distributed factors\n### these are just to help me set the indicators\n### the f1 and f2 will not be included in the data.frame\nf1 <- rnorm(250)\nf2 <- rnorm(250)\n\n### f1 indicators x1 to x3\nx1 <- f1 + rnorm(250, sd=0.15)\nx2 <- f1 + rnorm(250, sd=0.15)\nx3 <- f1 + rnorm(250, sd=0.15)\n\n### f2 indicators x4 to x6\nx4 <- f2 + rnorm(250, sd=0.15)\nx5 <- f2 + rnorm(250, sd=0.15)\nx6 <- f2 + rnorm(250, sd=0.15)\n\n### creating the dataframe\ndf <- data.frame(x1=x1, x2=x2, x3=x3, x4=x4, x5=x5, x6=x6)\n```\n:::\n\n\n## One factor CFA\n\n![](onefactor.JPG)\n\n## One factor CFA, expanded\n\n![](onefactor1.JPG)\n\n## Once factor CFA, expanded (again)\n\n![](onefactor2.JPG)\n\n## One Factor CFA and degrees of freedom\n\n1.  **df \\< 0**, the model is under-identified\n2.  **df = 0**, the model is just-identified (also known as saturated), no model fit\n3.  **df \\> 0**, over-identified, we can assess model fit\n\nReminder: **df = number of known values - number of parameters to estimate**\n\n## One Factor CFA and degrees of freedom\n\n1.  Total number of parameters (alson knows as \"known values\") as previously discussed\n\n    $$\n    p(p+1)/2\n    $$ $$\n    3(4)/2=6\n    $$\n\n2.  Number of parameters to estimate???? (Let us revisit the slide with the model visualisation)\n\n## Identification Methods\n\n1.  **marker method:** we fix the first loading of each factor to 1 (what does this mean?)\n2.  **variance standardization method:** we fix the variance of each factor to 1 and we freely estimate all other loadings (what does this mean?)\n3.  **standardization all method**, standardizes the variance of each factor to 1 but also standardizes the items\n\n**Note: default lavaan method is the marker method**\n\n## Let us see this example in lavaan\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lavaan)\n\nmodel1 <- '\nf1 =~ x1 + x2 + x3\n'\n\nmodel1.fit <- cfa(model1, data = df)\n\nsummary(model1.fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nlavaan 0.6.17 ended normally after 50 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         6\n\n  Number of observations                           250\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)\n  f1 =~                                               \n    x1                1.000                           \n    x2                0.992    0.014   72.880    0.000\n    x3                0.991    0.014   72.206    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)\n   .x1                0.019    0.003    6.471    0.000\n   .x2                0.023    0.003    7.277    0.000\n   .x3                0.023    0.003    7.424    0.000\n    f1                0.912    0.083   10.951    0.000\n```\n:::\n:::\n\n\n## How can we interpret this output?\n\n1.  x1 estimate is 1.000 and has no std error, z-value, nor p-value. This is because lavaan uses the **marker method by default**. x1 has been fixed to 1 and is now the scale of our factor 1.\n2.  x2 estimate is 0.992. For an increase of **1 unit** in **f1**, x2 increases by 0.992. The 1 unit in f1 is the unit of x1 as this was set to be the scale\n3.  .x1 refers to residual variances, hence the . in front of x1\n4.  f estimate of 0.912 is the variance of our latent variable (factor)\n5.  p-values are just telling us if our estimates are significantly greater than zero\n\nBut what about intercept???\n\n## Adding intercept in lavaan\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lavaan)\n\nmodel1.inter <- '\nf1 =~ x1 + x2 + x3\nf1 ~ 1 \n'\n\nmodel1.inter.fit <- cfa(model1.inter, data = df)\n\nsummary(model1.inter.fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nlavaan 0.6.17 ended normally after 50 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        10\n\n  Number of observations                           250\n\nModel Test User Model:\n                                                      \n  Test statistic                                    NA\n  Degrees of freedom                                -1\n  P-value (Unknown)                                 NA\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)\n  f1 =~                                               \n    x1                1.000                           \n    x2                0.992       NA                  \n    x3                0.991       NA                  \n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(>|z|)\n    f1                0.000       NA                  \n   .x1                0.009       NA                  \n   .x2                0.036       NA                  \n   .x3                0.014       NA                  \n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)\n   .x1                0.019       NA                  \n   .x2                0.023       NA                  \n   .x3                0.023       NA                  \n    f1                0.912       NA                  \n```\n:::\n:::\n\n\n## What about **variance standardization method**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lavaan)\n\nmodel1.var <- '\nf1 =~ NA*x1 + x2 + x3\nf1 ~~ 1*f1 \n'\n\nmodel1.var.fit <- cfa(model1.var, data = df)\n\nsummary(model1.var.fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nlavaan 0.6.17 ended normally after 30 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         6\n\n  Number of observations                           250\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)\n  f1 =~                                               \n    x1                0.955    0.044   21.901    0.000\n    x2                0.948    0.043   21.811    0.000\n    x3                0.946    0.043   21.792    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)\n    f1                1.000                           \n   .x1                0.019    0.003    6.471    0.000\n   .x2                0.023    0.003    7.277    0.000\n   .x3                0.023    0.003    7.424    0.000\n```\n:::\n:::\n\n\n## Thanks for nothing Laz!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel1 <- '\nf1 =~ x1 + x2 + x3\n'\n\nmodel1.fit <- cfa(model1, std.lv=TRUE, data = df)\n\nsummary(model1.fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nlavaan 0.6.17 ended normally after 30 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         6\n\n  Number of observations                           250\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)\n  f1 =~                                               \n    x1                0.955    0.044   21.901    0.000\n    x2                0.948    0.043   21.811    0.000\n    x3                0.946    0.043   21.792    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)\n   .x1                0.019    0.003    6.471    0.000\n   .x2                0.023    0.003    7.277    0.000\n   .x3                0.023    0.003    7.424    0.000\n    f1                1.000                           \n```\n:::\n:::\n\n\n## Interpretation\n\nRemember this method standardizes our factor, so we will need to speak in terms of standard deviations\n\n**x1 estimate of 0.955**: For an increase of 1 standard deviation in **f1**, x1 increases by 0.955\n\n## And the magnificent standardization all walks in\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel1 <- '\nf1 =~ x1 + x2 + x3\n'\n\nmodel1.fit <- cfa(model1, data = df)\n\nsummary(model1.fit, standardized=TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nlavaan 0.6.17 ended normally after 50 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         6\n\n  Number of observations                           250\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n  f1 =~                                                                 \n    x1                1.000                               0.955    0.990\n    x2                0.992    0.014   72.880    0.000    0.948    0.988\n    x3                0.991    0.014   72.206    0.000    0.946    0.987\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   .x1                0.019    0.003    6.471    0.000    0.019    0.020\n   .x2                0.023    0.003    7.277    0.000    0.023    0.024\n   .x3                0.023    0.003    7.424    0.000    0.023    0.025\n    f1                0.912    0.083   10.951    0.000    1.000    1.000\n```\n:::\n:::\n\n\n## Moving on to Model fit statistics\n\nAs things are now we cannot obtain model fit statistics as **df =0**\n\nSo our model is just-identified (saturated)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel2 <- '\nf1 =~ x1 + x2 + x3 + x4\nf2 =~ x5 + x6\n'\n\nmodel2.fit <- cfa(model2, data = df)\nsummary(model2.fit, standardized=TRUE, fit.measures=TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nlavaan 0.6.17 ended normally after 48 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        13\n\n  Number of observations                           250\n\nModel Test User Model:\n                                                      \n  Test statistic                               812.060\n  Degrees of freedom                                 8\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                              3202.055\n  Degrees of freedom                                15\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.748\n  Tucker-Lewis Index (TLI)                       0.527\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)               -889.645\n  Loglikelihood unrestricted model (H1)       -483.616\n                                                      \n  Akaike (AIC)                                1805.291\n  Bayesian (BIC)                              1851.070\n  Sample-size adjusted Bayesian (SABIC)       1809.859\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.634\n  90 Percent confidence interval - lower         0.598\n  90 Percent confidence interval - upper         0.671\n  P-value H_0: RMSEA <= 0.050                    0.000\n  P-value H_0: RMSEA >= 0.080                    1.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.299\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n  f1 =~                                                                 \n    x1                1.000                               0.955    0.990\n    x2                0.992    0.014   72.869    0.000    0.948    0.988\n    x3                0.991    0.014   72.277    0.000    0.946    0.987\n    x4               -0.090    0.065   -1.397    0.162   -0.086   -0.088\n  f2 =~                                                                 \n    x5                1.000                               0.960    0.961\n    x6                1.028    0.185    5.548    0.000    0.986    1.017\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n  f1 ~~                                                                 \n    f2               -0.072    0.061   -1.180    0.238   -0.078   -0.078\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   .x1                0.019    0.003    6.451    0.000    0.019    0.020\n   .x2                0.023    0.003    7.296    0.000    0.023    0.025\n   .x3                0.023    0.003    7.424    0.000    0.023    0.025\n   .x4                0.947    0.085   11.180    0.000    0.947    0.992\n   .x5                0.076    0.166    0.456    0.648    0.076    0.076\n   .x6               -0.032    0.175   -0.183    0.855   -0.032   -0.034\n    f1                0.912    0.083   10.952    0.000    1.000    1.000\n    f2                0.921    0.188    4.903    0.000    1.000    1.000\n```\n:::\n:::\n\n\n## What if we make sure there is no covariance between factors?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel2.nocov <- '\nf1 =~ x1 + x2 + x3 + x4\nf2 =~ x5 + x6\nf1~~0*f2\n'\n\nmodel2.nocov.fit <- cfa(model2.nocov, data = df)\nsummary(model2.nocov.fit, standardized=TRUE, fit.measures=TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nlavaan 0.6.17 ended normally after 52 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        12\n\n  Number of observations                           250\n\nModel Test User Model:\n                                                      \n  Test statistic                               813.666\n  Degrees of freedom                                 9\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                              3202.055\n  Degrees of freedom                                15\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.748\n  Tucker-Lewis Index (TLI)                       0.579\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)               -890.449\n  Loglikelihood unrestricted model (H1)       -483.616\n                                                      \n  Akaike (AIC)                                1804.898\n  Bayesian (BIC)                              1847.155\n  Sample-size adjusted Bayesian (SABIC)       1809.114\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.598\n  90 Percent confidence interval - lower         0.564\n  90 Percent confidence interval - upper         0.633\n  P-value H_0: RMSEA <= 0.050                    0.000\n  P-value H_0: RMSEA >= 0.080                    1.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.303\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n  f1 =~                                                                 \n    x1                1.000                               0.955    0.990\n    x2                0.992       NA                      0.948    0.988\n    x3                0.991       NA                      0.946    0.987\n    x4               -0.090       NA                     -0.086   -0.088\n  f2 =~                                                                 \n    x5                1.000                               0.921    0.923\n    x6                1.116       NA                      1.028    1.060\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n  f1 ~~                                                                 \n    f2                0.000                               0.000    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   .x1                0.019       NA                      0.019    0.020\n   .x2                0.023       NA                      0.023    0.025\n   .x3                0.023       NA                      0.023    0.025\n   .x4                0.948       NA                      0.948    0.992\n   .x5                0.148       NA                      0.148    0.149\n   .x6               -0.115       NA                     -0.115   -0.123\n    f1                0.912       NA                      1.000    1.000\n    f2                0.848       NA                      1.000    1.000\n```\n:::\n:::\n\n\n## Can we improve our model?\n\nOne way to do that is to look into our model residuals. Model residuals are an **absolute fit index** where we compare our model with th observed data. Generally, you regard **absolute goodness of fit** as the \"discrepancy\" between our model and the observed data. Higher residuals indicate greater discrepancy.\n\nSo how high is bad? We can request either **correlations** or **standardized residuals**.\n\n## Correlations\n\nHere both observed and estimated covariances are converted into correlations and then we calculate the differences. Greater differences indicate problematic items.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresiduals(model2.fit, type=\"cor\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$type\n[1] \"cor.bollen\"\n\n$cov\n       x1     x2     x3     x4     x5     x6\nx1  0.000                                   \nx2  0.000  0.000                            \nx3  0.000  0.000  0.000                     \nx4 -0.010  0.013  0.001  0.000              \nx5 -0.010  0.015  0.000  0.967  0.000       \nx6 -0.010  0.015 -0.002  0.968  0.000  0.000\n```\n:::\n:::\n\n\n## Standardized residuals\n\nHere we standardize the covariance and in practice treat it as a z-score, values greater than 1.96 indicate problematic cases.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresiduals(model2.fit, type=\"standardized\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$type\n[1] \"standardized\"\n\n$cov\n       x1     x2     x3     x4     x5     x6\nx1  0.000                                   \nx2  0.000  0.000                            \nx3 -1.636  1.394  0.000                     \nx4 -1.342  1.533  0.108  0.000              \nx5 -1.462  1.783  0.010 11.027  0.000       \nx6 -1.347  1.868 -0.199 11.039  0.000  0.000\n```\n:::\n:::\n\n\n## Modification Indices\n\nWe should look at modification indices that give as an estimate change of our chi-square value if we make changes to our model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodificationindices(model2.fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   lhs op rhs      mi    epc sepc.lv sepc.all sepc.nox\n18  f2 =~  x1   1.522 -0.014  -0.013   -0.014   -0.014\n19  f2 =~  x2   3.561  0.022   0.021    0.022    0.022\n20  f2 =~  x3   0.117 -0.004  -0.004   -0.004   -0.004\n21  f2 =~  x4 225.561  0.939   0.901    0.923    0.923\n22  x1 ~~  x2   0.105  0.030   0.030    1.446    1.446\n23  x1 ~~  x3   5.001 -0.204  -0.204   -9.753   -9.753\n24  x1 ~~  x4   1.821 -0.015  -0.015   -0.109   -0.109\n25  x1 ~~  x5   0.481 -0.002  -0.002   -0.043   -0.043\n26  x1 ~~  x6   0.153  0.001   0.001    0.036    0.036\n27  x2 ~~  x3   3.971  0.173   0.173    7.516    7.516\n28  x2 ~~  x4   2.366  0.017   0.017    0.117    0.117\n29  x2 ~~  x5   0.042  0.000   0.000   -0.012   -0.012\n30  x2 ~~  x6   0.357  0.001   0.001    0.052    0.052\n31  x3 ~~  x4   0.012  0.001   0.001    0.008    0.008\n32  x3 ~~  x5   0.931  0.002   0.002    0.056    0.056\n33  x3 ~~  x6   0.970 -0.002  -0.002   -0.085   -0.085\n34  x4 ~~  x5   2.227  0.019   0.019    0.072    0.072\n35  x4 ~~  x6   3.243  0.023   0.023    0.130    0.130\n```\n:::\n:::\n\n\n## Modifying the model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel2.1 <- '\nf1 =~ x1 + x2 + x3 \nf2 =~ x4 + x5 + x6\n'\n\nmodel2.1.fit <- cfa(model2.1, data = df)\nsummary(model2.1.fit, standardized=TRUE, fit.measures=TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nlavaan 0.6.17 ended normally after 58 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        13\n\n  Number of observations                           250\n\nModel Test User Model:\n                                                      \n  Test statistic                                 7.569\n  Degrees of freedom                                 8\n  P-value (Chi-square)                           0.477\n\nModel Test Baseline Model:\n\n  Test statistic                              3202.055\n  Degrees of freedom                                15\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    1.000\n  Tucker-Lewis Index (TLI)                       1.000\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)               -487.400\n  Loglikelihood unrestricted model (H1)       -483.616\n                                                      \n  Akaike (AIC)                                1000.800\n  Bayesian (BIC)                              1046.579\n  Sample-size adjusted Bayesian (SABIC)       1005.368\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.000\n  90 Percent confidence interval - lower         0.000\n  90 Percent confidence interval - upper         0.072\n  P-value H_0: RMSEA <= 0.050                    0.817\n  P-value H_0: RMSEA >= 0.080                    0.025\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.007\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n  f1 =~                                                                 \n    x1                1.000                               0.955    0.990\n    x2                0.992    0.014   72.877    0.000    0.948    0.988\n    x3                0.991    0.014   72.242    0.000    0.946    0.987\n  f2 =~                                                                 \n    x4                1.000                               0.963    0.986\n    x5                1.024    0.015   66.812    0.000    0.986    0.988\n    x6                0.997    0.014   69.570    0.000    0.960    0.990\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n  f1 ~~                                                                 \n    f2               -0.074    0.059   -1.263    0.206   -0.081   -0.081\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   .x1                0.019    0.003    6.461    0.000    0.019    0.020\n   .x2                0.023    0.003    7.286    0.000    0.023    0.025\n   .x3                0.023    0.003    7.424    0.000    0.023    0.025\n   .x4                0.027    0.004    7.763    0.000    0.027    0.029\n   .x5                0.025    0.003    7.099    0.000    0.025    0.025\n   .x6                0.019    0.003    6.260    0.000    0.019    0.020\n    f1                0.912    0.083   10.951    0.000    1.000    1.000\n    f2                0.927    0.085   10.858    0.000    1.000    1.000\n```\n:::\n:::\n\n\n## Let us see if the residuals tell the same story\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresiduals(model2.1.fit, type=\"standardized\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$type\n[1] \"standardized\"\n\n$cov\n       x1     x2     x3     x4     x5     x6\nx1  0.000                                   \nx2  0.000  0.000                            \nx3 -1.669  1.497  0.000                     \nx4 -1.576  0.327 -0.624  0.000              \nx5 -0.533  1.678  0.406  0.000  0.000       \nx6 -0.907  1.477 -0.104 -0.684  0.861  0.000\n```\n:::\n:::\n\n\n## What about modification indices\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodificationindices(model2.1.fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   lhs op rhs    mi    epc sepc.lv sepc.all sepc.nox\n16  f1 =~  x4 0.787 -0.012  -0.011   -0.011   -0.011\n17  f1 =~  x5 0.439  0.008   0.008    0.008    0.008\n18  f1 =~  x6 0.031  0.002   0.002    0.002    0.002\n19  f2 =~  x1 2.236 -0.017  -0.017   -0.017   -0.017\n20  f2 =~  x2 2.856  0.020   0.020    0.020    0.020\n21  f2 =~  x3 0.016 -0.002  -0.001   -0.002   -0.002\n22  x1 ~~  x2 0.016  0.017   0.017    0.839    0.839\n23  x1 ~~  x3 2.856 -0.229  -0.229  -10.923  -10.923\n24  x1 ~~  x4 0.031  0.000   0.000    0.016    0.016\n25  x1 ~~  x5 0.476 -0.001  -0.001   -0.067   -0.067\n26  x1 ~~  x6 0.051  0.000   0.000    0.023    0.023\n27  x2 ~~  x3 2.236  0.192   0.192    8.386    8.386\n28  x2 ~~  x4 1.923 -0.003  -0.003   -0.124   -0.124\n29  x2 ~~  x5 0.174  0.001   0.001    0.039    0.039\n30  x2 ~~  x6 1.393  0.002   0.002    0.116    0.116\n31  x3 ~~  x4 1.090  0.002   0.002    0.093    0.093\n32  x3 ~~  x5 0.189  0.001   0.001    0.040    0.040\n33  x3 ~~  x6 1.946 -0.003  -0.003   -0.136   -0.136\n34  x4 ~~  x5 0.031 -0.024  -0.024   -0.941   -0.941\n35  x4 ~~  x6 0.439 -0.093  -0.093   -4.050   -4.050\n36  x5 ~~  x6 0.787  0.133   0.133    6.150    6.150\n```\n:::\n:::\n\n\n## Exercise\n\nLet us try a different model now. Go onto your posit cloud account and open the Week 5 project, follow the instructions and carry out the required CFA.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}