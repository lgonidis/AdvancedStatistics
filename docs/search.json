[
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "AdvancedStatistics",
    "section": "",
    "text": "Assignment 1\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nConfirmatory Factor Analysis\n\n\n\n\n\n\n\n\n\n\n\n\nFeb 19, 2024\n\n\nDr Lazaros Gonidis\n\n\n\n\n\n\n  \n\n\n\n\nExploratory Factor Analysis\n\n\n\n\n\n\n\n\n\n\n\n\nFeb 10, 2024\n\n\nDr Lazaros Gonidis\n\n\n\n\n\n\n  \n\n\n\n\nIntroduction to S.E.M\n\n\n\n\n\n\n\n\n\n\n\n\nFeb 7, 2024\n\n\nDr Lazaros Gonidis\n\n\n\n\n\n\n  \n\n\n\n\nIntroduction to Advanced Statistics\n\n\n\n\n\n\n\n\n\n\n\n\nFeb 1, 2024\n\n\nDr Lazaros Gonidis\n\n\n\n\n\n\n  \n\n\n\n\nIntroduction to Mediation\n\n\n\n\n\n\n\n\n\n\n\n\nJan 27, 2024\n\n\nDr Lazaros Gonidis\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/Introduction to Advanced Statistics/index.html#todays-aims",
    "href": "posts/Introduction to Advanced Statistics/index.html#todays-aims",
    "title": "Introduction to Advanced Statistics",
    "section": "Today’s Aims",
    "text": "Today’s Aims\n\nCanvas\nAssessment\nQuizzes\nRstudio/Posit\nGithub"
  },
  {
    "objectID": "posts/Introduction to Advanced Statistics/index.html#who-i-am",
    "href": "posts/Introduction to Advanced Statistics/index.html#who-i-am",
    "title": "Introduction to Advanced Statistics",
    "section": "",
    "text": "This is me (used to be)\nI love my two boys\nI also love computer games, motorbikes, music, food\nFunnily enough I love maths and statistics, and even more teaching these\nI am also dyslexic so please do tell me when you spot typing mistakes, usually whole words missing."
  },
  {
    "objectID": "posts/Introduction to Advanced Statistics/index.html#essential-and-supplamentary-materials",
    "href": "posts/Introduction to Advanced Statistics/index.html#essential-and-supplamentary-materials",
    "title": "Introduction to Advanced Statistics",
    "section": "Essential and Supplamentary Materials",
    "text": "Essential and Supplamentary Materials\n\n\n\n\n\n\nPrinciples and Practice of Structural Equation Modeling\nLongitudinal Structural Equation Modeling: A comprehensive Introduction\nOfficial lavaan tutorial from lavaan.org\nPsychometrics in Exercises using R and Rstudio by Prof Anna Brown\nIntroduction to Structural Equation Modeling (SEM) in R with lavaan by Dr Johnny Lin\n** And many other online resources that will be revealed in due time"
  },
  {
    "objectID": "posts/Introduction to Advanced Statistics/index.html#section",
    "href": "posts/Introduction to Advanced Statistics/index.html#section",
    "title": "Introduction to Advanced Statistics",
    "section": "",
    "text": "Multiple regression, lm()\n\nreading2_lm &lt;- lm(reading ~ income + books, data = df)\n\n\nsummary(reading2_lm)\n\n\nCall:\nlm(formula = reading ~ income + books, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-50.397 -13.633   0.547  13.698  51.585 \n\nCoefficients:\n             Estimate Std. Error t value             Pr(&gt;|t|)    \n(Intercept) 187.28030    6.14063  30.499 &lt; 0.0000000000000002 ***\nincome        0.06160    0.01997   3.085              0.00265 ** \nbooks         6.14601    1.40272   4.382            0.0000298 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 19.69 on 97 degrees of freedom\nMultiple R-squared:  0.4487,    Adjusted R-squared:  0.4373 \nF-statistic: 39.47 on 2 and 97 DF,  p-value: 0.0000000000002875"
  },
  {
    "objectID": "posts/Introduction to Advanced Statistics/index.html#todays-aims-in-terms-of-the-module",
    "href": "posts/Introduction to Advanced Statistics/index.html#todays-aims-in-terms-of-the-module",
    "title": "Introduction to Advanced Statistics",
    "section": "Today’s Aims in Terms of the Module",
    "text": "Today’s Aims in Terms of the Module\n\nCanvas\nRstudio/Posit\ndiscord\nAssessment\nQuizzes (Badges to be confirmed)\nGithub"
  },
  {
    "objectID": "posts/Introduction to Advanced Statistics/index.html#todays-aims-in-terms-of-sem",
    "href": "posts/Introduction to Advanced Statistics/index.html#todays-aims-in-terms-of-sem",
    "title": "Introduction to Advanced Statistics",
    "section": "Today’s Aims in Terms of SEM",
    "text": "Today’s Aims in Terms of SEM\n\nIntroduce key terminology that we will be using this term\nDiscuss an example of simple regression\nRevisit the same example using lavaan\nDiscuss baximum likelihood vs. least squares"
  },
  {
    "objectID": "posts/Introduction to Advanced Statistics/index.html#key-terminology",
    "href": "posts/Introduction to Advanced Statistics/index.html#key-terminology",
    "title": "Introduction to Advanced Statistics",
    "section": "Key Terminology",
    "text": "Key Terminology\nWe will be using quite a few terms in our module so it is important to define them in advance and try to use them consistently. Most of the them are used as in the field but you could come across some slight variations in terminology. This should not put you off or scare you, as long as you understand the substance of each term. It is also a good idea to try to learn the visual equivalents of these terms"
  },
  {
    "objectID": "posts/Introduction to Advanced Statistics/index.html#key-terminology-2",
    "href": "posts/Introduction to Advanced Statistics/index.html#key-terminology-2",
    "title": "Introduction to Advanced Statistics",
    "section": "Key Terminology 2",
    "text": "Key Terminology 2\n\n\n\n\n\nlatent variable: a variable that is constructed/inferred indirectly by the data and does not exist in the data.\nobserved variable: a variable that has been measured and exists in our data.\nexogenous variable: an independent variable that explains an endogenous variable. Can be either observed \\((x)\\) or latent \\((ξ)\\).\nendogenous variable: a dependent variable that has a causal path leading to it. Can be either observed \\((y)\\) or latent \\((η)\\).\nmeasurement model: a model that links observed variables with latent variables"
  },
  {
    "objectID": "posts/Introduction to Advanced Statistics/index.html#key-terminology-3",
    "href": "posts/Introduction to Advanced Statistics/index.html#key-terminology-3",
    "title": "Introduction to Advanced Statistics",
    "section": "Key Terminology 3",
    "text": "Key Terminology 3\n\n\n\n\n\nindicator: an observed variable in a measurement model (can be exogenous or endogenous).\nfactor: a latent variable defined by its indicators (can be exogenous or endogenous).\nloading: a path between an indicator and a factor.\nstructural model: a model that specifies causal relationships among exogenous variables to endogenous variables (can be observed or latent).\nregression path: a path between exogenous and endogenous variables (can be observed or latent)."
  },
  {
    "objectID": "posts/Introduction to Advanced Statistics/index.html#are-you-ready-for-the-first-headache-question",
    "href": "posts/Introduction to Advanced Statistics/index.html#are-you-ready-for-the-first-headache-question",
    "title": "Introduction to Advanced Statistics",
    "section": "Are you ready for the first headache question?",
    "text": "Are you ready for the first headache question?\nSo far, in linear regression we have learnt that \\(x\\) is an independent variable and \\(y\\) the dependent variable or outcome. However, in measurement models, the use of \\(x\\) or \\(y\\) depends on the type of factor we are referring to. If an indicator depends on an exogenous factor, the we refer to it as \\(x\\)-side. If an indicator depends on an endogenous factor then we refer to it as \\(y\\)-side."
  },
  {
    "objectID": "posts/Introduction to Advanced Statistics/index.html#let-us-expand-on-this-headache-a-bit-more",
    "href": "posts/Introduction to Advanced Statistics/index.html#let-us-expand-on-this-headache-a-bit-more",
    "title": "Introduction to Advanced Statistics",
    "section": "Let us expand on this headache a bit more",
    "text": "Let us expand on this headache a bit more"
  },
  {
    "objectID": "posts/Introduction to Advanced Statistics/index.html#simple-regression",
    "href": "posts/Introduction to Advanced Statistics/index.html#simple-regression",
    "title": "Introduction to Advanced Statistics",
    "section": "Simple Regression",
    "text": "Simple Regression\nSo far we have learnt that a simple regression is the linear relation between a predictor (or an independent variable, or an observed exogenous variable) and an outcome (or observed endogenous variable).\n\\[\ny_1 = b_0 +b_1x_1 + ε_1\n\\]\nwhere \\(b_0\\) is the intercept and \\(b_1\\) is the coefficient of \\(x_1\\) (observed predictor) and \\(ε_1\\) is the residual with \\(y_1\\) being the outcome."
  },
  {
    "objectID": "posts/Introduction to Advanced Statistics/index.html#simple-regression-cont.",
    "href": "posts/Introduction to Advanced Statistics/index.html#simple-regression-cont.",
    "title": "Introduction to Advanced Statistics",
    "section": "Simple Regression cont.",
    "text": "Simple Regression cont.\nI strongly recommend reading Kline chapter 2, pages 25-30 at minimum, Regression Fundamentals.\n\\[\n\\hat{Y} = B_XX + A_X\n\\]\nThe above equation represents predicting Y from X\nAlso referred to as regressing Y on X, with \\(\\hat{Y}\\) representing predicted scores, \\(B_X\\) unstandardised regression coefficient for predictor \\(X\\), also known as slope, and \\(A_X\\) is the intercept.\nGenerally, with linear models we would use ordinary least square (OLS) so that the least squares criterion is satisfied. In practice, we are trying to minimise the sum of squared residuals, \\(\\sum(Y-\\hat{Y})\\)"
  },
  {
    "objectID": "posts/Introduction to Advanced Statistics/index.html#let-us-see-an-example-with-data",
    "href": "posts/Introduction to Advanced Statistics/index.html#let-us-see-an-example-with-data",
    "title": "Introduction to Advanced Statistics",
    "section": "Let us see an example with data",
    "text": "Let us see an example with data\nWe will work with the randomly generated data included in the random.csv\nThe datafile includes three variables:\nreading: reading ability as assessed in school\nincome: weekly family income in £\nbooks: number of books read in a month (on average)\nWe will create a simple regression model of reading  regressing on income using lm()"
  },
  {
    "objectID": "posts/Introduction to Advanced Statistics/index.html#loading-the-datafile",
    "href": "posts/Introduction to Advanced Statistics/index.html#loading-the-datafile",
    "title": "Introduction to Advanced Statistics",
    "section": "Loading the datafile",
    "text": "Loading the datafile\n\nlibrary(tidyverse)\nlibrary(lavaan)\ndf &lt;- read_csv(\"random.csv\")"
  },
  {
    "objectID": "posts/Introduction to Advanced Statistics/index.html#creating-the-model-and-getting-model-parameters",
    "href": "posts/Introduction to Advanced Statistics/index.html#creating-the-model-and-getting-model-parameters",
    "title": "Introduction to Advanced Statistics",
    "section": "Creating the model and getting model parameters",
    "text": "Creating the model and getting model parameters\n\nreading_lm &lt;- lm(reading ~ income, data = df)\n# the option below instructs R to give us the output in non-exponential notation\noptions(scipen=999)\n\nsummary(reading_lm)\n\n\nCall:\nlm(formula = reading ~ income, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-50.590 -16.562  -0.178  13.429  48.207 \n\nCoefficients:\n             Estimate Std. Error t value             Pr(&gt;|t|)    \n(Intercept) 188.17787    6.68278  28.159 &lt; 0.0000000000000002 ***\nincome        0.11800    0.01662   7.098       0.000000000201 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 21.44 on 98 degrees of freedom\nMultiple R-squared:  0.3395,    Adjusted R-squared:  0.3328 \nF-statistic: 50.38 on 1 and 98 DF,  p-value: 0.0000000002013"
  },
  {
    "objectID": "posts/Introduction to Advanced Statistics/index.html#looking-at-the-output",
    "href": "posts/Introduction to Advanced Statistics/index.html#looking-at-the-output",
    "title": "Introduction to Advanced Statistics",
    "section": "Looking at the output",
    "text": "Looking at the output\nOur intercept is 188.18 and our income coefficient is 0.118 (0.12). This means that the reading ability of a student with a family income of £0 will be 188.18 and for every £1 of family income increase the reading ability will increase by 0.12.\nWe also see residual standard error of 21.44\nThe square of that value is 459.67"
  },
  {
    "objectID": "posts/Introduction to Advanced Statistics/index.html#let-us-recreate-the-same-model-using-lavaan",
    "href": "posts/Introduction to Advanced Statistics/index.html#let-us-recreate-the-same-model-using-lavaan",
    "title": "Introduction to Advanced Statistics",
    "section": "Let us recreate the same model using Lavaan",
    "text": "Let us recreate the same model using Lavaan\n\n# lavaan uses a simple language when specifying the model\n#simple regression using lavaan \nreading_lav &lt;-   '\n  # regressions\n    reading ~ 1 + income\n  # variance (optional)\n    income ~~ income\n'\nreading_lav_sem &lt;- sem(reading_lav, data=df)\nsummary(reading_lav_sem)\n\nlavaan 0.6.17 ended normally after 11 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         5\n\n  Number of observations                           100\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nRegressions:\n                   Estimate   Std.Err  z-value  P(&gt;|z|)\n  reading ~                                            \n    income             0.118    0.016    7.170    0.000\n\nIntercepts:\n                   Estimate   Std.Err  z-value  P(&gt;|z|)\n   .reading          188.178    6.616   28.445    0.000\n    income           380.752   12.896   29.525    0.000\n\nVariances:\n                   Estimate   Std.Err  z-value  P(&gt;|z|)\n    income         16630.573 2351.918    7.071    0.000\n   .reading          450.401   63.696    7.071    0.000"
  },
  {
    "objectID": "posts/Introduction to Advanced Statistics/index.html#let-us-recreate-the-same-model-using-lavaan-1",
    "href": "posts/Introduction to Advanced Statistics/index.html#let-us-recreate-the-same-model-using-lavaan-1",
    "title": "Introduction to Advanced Statistics",
    "section": "Let us recreate the same model using Lavaan",
    "text": "Let us recreate the same model using Lavaan\n\n\nCode\n# lavaan uses a simple language when specifying the model\n#simple regression using lavaan \nreading_lav &lt;-   '\n  # regressions\n    reading ~ 1 + income\n  # variance (optional)\n    income ~~ income\n'\nreading_lav_sem &lt;- sem(reading_lav, data=df)\nsummary(reading_lav_sem)\n\n\nlavaan 0.6.17 ended normally after 11 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         5\n\n  Number of observations                           100\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nRegressions:\n                   Estimate      Std.Err  z-value  P(&gt;|z|)\n  reading ~                                               \n    income                0.002 NA                        \n\nIntercepts:\n                   Estimate      Std.Err  z-value  P(&gt;|z|)\n   .reading             188.180 NA                        \n    income            19037.628 NA                        \n\nVariances:\n                   Estimate      Std.Err  z-value  P(&gt;|z|)\n    income         41576275.335 NA                        \n   .reading             450.395 NA"
  },
  {
    "objectID": "posts/Introduction to Advanced Statistics/index.html#comparing-the-two-outputs",
    "href": "posts/Introduction to Advanced Statistics/index.html#comparing-the-two-outputs",
    "title": "Introduction to Advanced Statistics",
    "section": "Comparing the two outputs",
    "text": "Comparing the two outputs\nWe observe that the estimates of the regression coefficients are the same despite lm() using least squares (LS) and lavaan using maximum likelihood (ML). However the variances are different with 459.67 for lm() and 450.40 for lavaan.\nIn we want to convert from LS variance to ML variance we can use the following formula\n\\[\n\\hat{σ}_{ML}^2 = \\frac{(N-k)}{n}\\hat{σ}_{LS}^2\n\\]\nWhere \\(N\\) and \\(n\\) are the sample sizes and \\(k\\) is the number or parameters to estimate, in this case \\(k\\)=2, one intercept and one regression coefficient\n\\[\n\\hat{σ}_{ML}^2 = \\frac{(100-2)}{100}21.44^2=450.48\n\\]"
  },
  {
    "objectID": "posts/Introduction to Advanced Statistics/index.html#visualising",
    "href": "posts/Introduction to Advanced Statistics/index.html#visualising",
    "title": "Introduction to Advanced Statistics",
    "section": "Visualising",
    "text": "Visualising\n\n\nCode\nlibrary(semPlot)\n\nsemPaths(reading_lav_sem,\n         whatLabels = \"est\",\n         sizeMan = 10,\n         style = \"ram\",\n         layout = \"circle\")"
  },
  {
    "objectID": "posts/Introduction to Advanced Statistics/index.html#multiple-regression",
    "href": "posts/Introduction to Advanced Statistics/index.html#multiple-regression",
    "title": "Introduction to Advanced Statistics",
    "section": "Multiple regression",
    "text": "Multiple regression\nWe can expand the previous example to now include a second predictor, books which represents the number of books read"
  },
  {
    "objectID": "posts/Introduction to Advanced Statistics/index.html#visualising-with-sempaths-from-semplot",
    "href": "posts/Introduction to Advanced Statistics/index.html#visualising-with-sempaths-from-semplot",
    "title": "Introduction to Advanced Statistics",
    "section": "Visualising with semPaths() from semPlot",
    "text": "Visualising with semPaths() from semPlot\n\nlibrary(semPlot)\n\nsemPaths(reading_lav_sem,\n         whatLabels = \"est\",\n         sizeMan = 10,\n         style = \"ram\",\n         layout = \"circle\")"
  },
  {
    "objectID": "posts/Introduction to Advanced Statistics/index.html#multiple-regression-lm",
    "href": "posts/Introduction to Advanced Statistics/index.html#multiple-regression-lm",
    "title": "Introduction to Advanced Statistics",
    "section": "Multiple regression, lm()",
    "text": "Multiple regression, lm()\nWe can expand the previous example to now include a second predictor, books which represents the number of books read in a month (on average)\n\\[\ny_1 = b_0 +b_1x_1 + b_2x_2 + ε_1\n\\]\nYou may also come across the following notation:\n\\[\n\\hat{Y} = B_XX + +B_WW + A_{X,W}\n\\]\nImportant to note here that \\(B_X\\) and \\(B_W\\) are the unstandardized partial regression coefficients, \\(A_{X,W}\\) is the intercept. For more information please read Kline page 30."
  },
  {
    "objectID": "posts/Introduction to Advanced Statistics/index.html#multiple-regression-lavaan",
    "href": "posts/Introduction to Advanced Statistics/index.html#multiple-regression-lavaan",
    "title": "Introduction to Advanced Statistics",
    "section": "Multiple regression, lavaan",
    "text": "Multiple regression, lavaan\n\nreading2_lav &lt;-   '\n  # regressions\n    reading ~ 1 + income + books\n  # covariance\n    income ~~ books\n'\nreading2_lav_sem &lt;- sem(reading2_lav, data=df)\nsummary(reading2_lav_sem)\n\nlavaan 0.6.17 ended normally after 38 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         9\n\n  Number of observations                           100\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nRegressions:\n                   Estimate   Std.Err  z-value  P(&gt;|z|)\n  reading ~                                            \n    income             0.062    0.020    3.132    0.002\n    books              6.146    1.382    4.449    0.000\n\nCovariances:\n                   Estimate   Std.Err  z-value  P(&gt;|z|)\n  income ~~                                            \n    books            152.610   28.168    5.418    0.000\n\nIntercepts:\n                   Estimate   Std.Err  z-value  P(&gt;|z|)\n   .reading          187.280    6.048   30.967    0.000\n    income           380.752   12.896   29.525    0.000\n    books              3.640    0.184   19.827    0.000\n\nVariances:\n                   Estimate   Std.Err  z-value  P(&gt;|z|)\n   .reading          375.988   53.173    7.071    0.000\n    income         16630.574 2351.918    7.071    0.000\n    books              3.370    0.477    7.071    0.000"
  },
  {
    "objectID": "posts/Introduction to Advanced Statistics/index.html#visualising-with-sempaths-from-semplot-1",
    "href": "posts/Introduction to Advanced Statistics/index.html#visualising-with-sempaths-from-semplot-1",
    "title": "Introduction to Advanced Statistics",
    "section": "Visualising with semPaths() from semPlot",
    "text": "Visualising with semPaths() from semPlot\n\nsemPaths(reading2_lav_sem,\n         whatLabels = \"est\",\n         sizeMan = 10,\n         style = \"ram\",\n         layout = \"spring\")"
  },
  {
    "objectID": "posts/Introduction to Advanced Statistics/index.html#canvas",
    "href": "posts/Introduction to Advanced Statistics/index.html#canvas",
    "title": "Introduction to Advanced Statistics",
    "section": "Canvas",
    "text": "Canvas\nHopefully you should know where to find our Canvas website, but just in case:\nhttps://canvas.sussex.ac.uk/courses/26315/pages/module-home-page"
  },
  {
    "objectID": "posts/Introduction to Advanced Statistics/index.html#rstudioposit-cloud",
    "href": "posts/Introduction to Advanced Statistics/index.html#rstudioposit-cloud",
    "title": "Introduction to Advanced Statistics",
    "section": "RStudio/Posit Cloud",
    "text": "RStudio/Posit Cloud\nFor our analysis we will be using exclusively R and mainly Posit Cloud. However, I strongly believe that as future scientists you should also have locally installed RStudio/Posit, have it up to date and use that for your everyday work. I would also advise you to attend our workshops bringing your own laptops/tablets/mobile phones.\nYou can join our Posit Cloud Workspace by following this link:\nhttps://posit.cloud/spaces/469376/join?access_code=4YBUfhrNPGU2oWWw5Zym6bepaVV6izQ8O1KE6THK"
  },
  {
    "objectID": "posts/Introduction to Advanced Statistics/index.html#discord-as-our-mean-of-day-to-day-communication",
    "href": "posts/Introduction to Advanced Statistics/index.html#discord-as-our-mean-of-day-to-day-communication",
    "title": "Introduction to Advanced Statistics",
    "section": "Discord as our mean of day to day communication",
    "text": "Discord as our mean of day to day communication\nWe will be using discord as our main communication channel, please use it for any stats related questions. If you have any more sensitive questions please do not hesitate to email me at: L.Gonidis@Sussex.ac.uk\nYou can join us by following this link: https://discord.gg/9TV3xzMZ"
  },
  {
    "objectID": "posts/Introduction to Advanced Statistics/index.html#visualising-with-sempaths-from-semplot-2",
    "href": "posts/Introduction to Advanced Statistics/index.html#visualising-with-sempaths-from-semplot-2",
    "title": "Introduction to Advanced Statistics",
    "section": "Visualising with semPaths() from semPlot",
    "text": "Visualising with semPaths() from semPlot\n\nsemPaths(reading2_lav_sem,\n         whatLabels = \"est\",\n         sizeMan = 10,          \n         style = \"ram\",          \n         layout = \"tree\",\n         intercepts = FALSE)"
  },
  {
    "objectID": "posts/Introduction to Advanced Statistics/index.html#a-prelude-to-next-week.-mediation-with-lavaan",
    "href": "posts/Introduction to Advanced Statistics/index.html#a-prelude-to-next-week.-mediation-with-lavaan",
    "title": "Introduction to Advanced Statistics",
    "section": "A prelude to next week. Mediation with Lavaan",
    "text": "A prelude to next week. Mediation with Lavaan\nWe will explore whether the number of books read actually mediate the effect of income on reading ability. We will not go in depth today as we will discuss this topic next week in detail. We will just demonstrate how the code would change in lavaan.\n\nreading_med_model &lt;- ' # direct effect\n             reading ~ c*income\n           # mediator\n             books ~ a*income\n             reading ~ b*books\n           # indirect effect (a*b)\n             ab := a*b\n           # total effect\n             total := c + (a*b)\n         '\nreading_med &lt;- sem(reading_med_model, data = df)\nsummary(reading_med )\n\nlavaan 0.6.17 ended normally after 1 iteration\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         5\n\n  Number of observations                           100\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nRegressions:\n                   Estimate   Std.Err  z-value  P(&gt;|z|)\n  reading ~                                            \n    income     (c)     0.062    0.020    3.132    0.002\n  books ~                                              \n    income     (a)     0.009    0.001    8.431    0.000\n  reading ~                                            \n    books      (b)     6.146    1.382    4.449    0.000\n\nVariances:\n                   Estimate   Std.Err  z-value  P(&gt;|z|)\n   .reading          375.988   53.173    7.071    0.000\n   .books              1.970    0.279    7.071    0.000\n\nDefined Parameters:\n                   Estimate   Std.Err  z-value  P(&gt;|z|)\n    ab                 0.056    0.014    3.935    0.000\n    total              0.118    0.016    7.170    0.000"
  },
  {
    "objectID": "posts/Introduction to Advanced Statistics/index.html#let-us-visualise-the-above-model",
    "href": "posts/Introduction to Advanced Statistics/index.html#let-us-visualise-the-above-model",
    "title": "Introduction to Advanced Statistics",
    "section": "Let us visualise the above model",
    "text": "Let us visualise the above model\n\nsemPaths(reading_med,\n         whatLabels = \"est\",\n         sizeMan = 10,          \n         style = \"ram\",          \n         layout = \"tree\",\n         intercepts = FALSE,\n         rotation = 2)"
  },
  {
    "objectID": "posts/Introduction to Advanced Statistics/index.html#to-conclude",
    "href": "posts/Introduction to Advanced Statistics/index.html#to-conclude",
    "title": "Introduction to Advanced Statistics",
    "section": "To conclude",
    "text": "To conclude\nHopefully, this was a gentle introduction to the module and lavaan. We will be following a more formal approach in the coming weeks. In the meantime do spend some time this week to do the suggested reading and practice with R and lavaan in our Posit Cloud Workspace."
  },
  {
    "objectID": "posts/Introduction to Advanced Statistics/index.html#who-you-are",
    "href": "posts/Introduction to Advanced Statistics/index.html#who-you-are",
    "title": "Introduction to Advanced Statistics",
    "section": "Who you are",
    "text": "Who you are\nI have no idea who you are but I hope by the end of this module you will love statistics a bit more and you will appreciate even more why they are paramount for Psychological research."
  },
  {
    "objectID": "posts/Introduction to Advanced Statistics/index.html#assessment",
    "href": "posts/Introduction to Advanced Statistics/index.html#assessment",
    "title": "Introduction to Advanced Statistics",
    "section": "Assessment",
    "text": "Assessment\nThe module will be assessed exclusively by coursework. This will be in the form of three 1,000 words results sections. The deadlines are:\n\nReport 1, February 13th 16:00\nReport 2, March 14th 16:00\nReport 3, April 23rd 16:00\n\nAll submissions will be via Canvas submission points in the Assignments, Contributory E-Submission subsection. Each report topic will be released in our workshop the week prior to the submission deadline. Specifically, for Report 1 the topic will be Mediation/Moderation analysis using lavaan. You will receive detailed instructions on that next Monday."
  },
  {
    "objectID": "posts/Introduction to Advanced Statistics/index.html#quizzes-and-badgeshopefully",
    "href": "posts/Introduction to Advanced Statistics/index.html#quizzes-and-badgeshopefully",
    "title": "Introduction to Advanced Statistics",
    "section": "Quizzes and Badges(hopefully)",
    "text": "Quizzes and Badges(hopefully)\nEvery week there will be a Canvas quiz provided so you can practice and enhance your understanding. These are absolutely non-compulsory but do spend some time trying to complete them. You will also be collecting points while you complete these (and other Canvas activities) and at the end of the module the two students with the highest scores will receive a surprise present."
  },
  {
    "objectID": "posts/Introduction to Advanced Statistics/index.html#github",
    "href": "posts/Introduction to Advanced Statistics/index.html#github",
    "title": "Introduction to Advanced Statistics",
    "section": "Github",
    "text": "Github\nGithub has been increasingly becoming a standard in the world of coding and statistical analysis as it can serve both as a repository and a host of websites related to projects. We will have a very brief demonstration today and we will return next week and start using it as a standard in our module."
  },
  {
    "objectID": "posts/Introduction to Advanced Statistics/index.html#todays-aims-in-terms-of-structural-equation-modeling-sem",
    "href": "posts/Introduction to Advanced Statistics/index.html#todays-aims-in-terms-of-structural-equation-modeling-sem",
    "title": "Introduction to Advanced Statistics",
    "section": "Today’s Aims in Terms of Structural Equation Modeling (SEM)",
    "text": "Today’s Aims in Terms of Structural Equation Modeling (SEM)\n\nIntroduce key terminology that we will be using this term\nDiscuss examples of simple and multiple regression\nRevisit the same examples using lavaan\nDiscuss baximum likelihood vs. least squares"
  },
  {
    "objectID": "posts/Introduction to Advanced Statistics/index.html#ols-vs-ml",
    "href": "posts/Introduction to Advanced Statistics/index.html#ols-vs-ml",
    "title": "Introduction to Advanced Statistics",
    "section": "OLS vs ML",
    "text": "OLS vs ML\nGenerally in SEM, we use the maximum likelihood estimator (MLE). In this module we will be using the acronyms ML and MLE to denote the maximum likelihood estimator method. This method estimates model parameters by maximising the likelihood function. In other words, maximising the probability of observing our existing data points given specific parameter values. We will be discussing in details what these parameters are in SEM (e.g., coefficients, latent variable variances, etc.). It should also be noted that MLE is not the only estimation methods, other methods can also be successfully implemented, such as generalised least squares. We decided on the appropriate estimator based on our data characteristics and assumptions."
  },
  {
    "objectID": "posts/Introduction to Mediation (with lavaan)/index.html#todays-aims",
    "href": "posts/Introduction to Mediation (with lavaan)/index.html#todays-aims",
    "title": "Introduction to Mediation",
    "section": "Today’s Aims",
    "text": "Today’s Aims\n\nIntroduce the concept of Mediation\nDiscuss a Simple Mediation Model\nUse of basic path analysis for Mediation\nUse of lavaan for mediation\nSerial and parallel mediation"
  },
  {
    "objectID": "posts/Introduction to Mediation (with lavaan)/index.html#linear-models",
    "href": "posts/Introduction to Mediation (with lavaan)/index.html#linear-models",
    "title": "Introduction to Mediation",
    "section": "Linear models",
    "text": "Linear models\nSo far we have discussed linear models where a variable Y regresses on X\n\\[\ny = b_0 +b_1x_1 + ε\n\\]\nOr, variable Y regresses on more than one variables, X1, X2, …\n\\[\ny = b_0 +b_1x_1 + b_2x_2 + ε_1\n\\]"
  },
  {
    "objectID": "posts/Introduction to Mediation (with lavaan)/index.html#linear-models-1",
    "href": "posts/Introduction to Mediation (with lavaan)/index.html#linear-models-1",
    "title": "Introduction to Mediation",
    "section": "Linear models",
    "text": "Linear models\nThese models allowed us to test hypotheses where exogenous observed variables X1, X2, … would have an effect on an endogenous observed variable Y\nHowever, in this approach we did not examine for potential impact of X1 on X2, and consequently the impact of X2 on Y."
  },
  {
    "objectID": "posts/Introduction to Mediation (with lavaan)/index.html#the-simple-mediation-model",
    "href": "posts/Introduction to Mediation (with lavaan)/index.html#the-simple-mediation-model",
    "title": "Introduction to Mediation",
    "section": "The Simple Mediation Model",
    "text": "The Simple Mediation Model\nToday we will introduce a new concept where two predicting variables X and M predict an endogenous observed variable Y.\nFurthermore, variable X also influences variable M. We will be referring to variable M as our Mediator.\nIt is also worth noting here that different sources and approaches are even stricter on the above by also requesting that these relations are causal.\nIn other words, X causally influences M and Y, and M causally influences Y."
  },
  {
    "objectID": "posts/Introduction to Mediation (with lavaan)/index.html#the-simple-mediation-model-visually",
    "href": "posts/Introduction to Mediation (with lavaan)/index.html#the-simple-mediation-model-visually",
    "title": "Introduction to Mediation",
    "section": "The Simple Mediation Model visually",
    "text": "The Simple Mediation Model visually"
  },
  {
    "objectID": "posts/Introduction to Mediation (with lavaan)/index.html#guidelines-prior-to-carry-out-mediation-analysis",
    "href": "posts/Introduction to Mediation (with lavaan)/index.html#guidelines-prior-to-carry-out-mediation-analysis",
    "title": "Introduction to Mediation",
    "section": "Guidelines prior to carry out mediation analysis",
    "text": "Guidelines prior to carry out mediation analysis\n\n\n\n\n\n\nX should significantly predict Y (path c, although some authors argue this is not required)*\nX must significantly predict M (path a)\nM must significantly predict Y (path b)\nNote: Typically the path above is called c path, whereas the direct path in the mediation would be called c’ path. However, you will mostly be seeing the direct path in the mediation models also being called c path as well. Please be aware of this."
  },
  {
    "objectID": "posts/Introduction to Mediation (with lavaan)/index.html#quizzes-and-badgeshopefully",
    "href": "posts/Introduction to Mediation (with lavaan)/index.html#quizzes-and-badgeshopefully",
    "title": "Introduction to Mediation",
    "section": "Quizzes and Badges(hopefully)",
    "text": "Quizzes and Badges(hopefully)\nEvery week there will be a Canvas quiz provided so you can practice and enhance your understanding. These are absolutely non-compulsory but do spend some time trying to complete them. You will also be collecting points while you complete these (and other Canvas activities) and at the end of the module the two students with the highest scores will receive a surprise present."
  },
  {
    "objectID": "posts/Introduction to Mediation (with lavaan)/index.html#github",
    "href": "posts/Introduction to Mediation (with lavaan)/index.html#github",
    "title": "Introduction to Mediation",
    "section": "Github",
    "text": "Github\nGithub has been increasingly becoming a standard in the world of coding and statistical analysis as it can serve both as a repository and a host of websites related to projects. We will have a very brief demonstration today and we will return next week and start using it as a standard in our module."
  },
  {
    "objectID": "posts/Introduction to Mediation (with lavaan)/index.html#essential-and-supplamentary-materials",
    "href": "posts/Introduction to Mediation (with lavaan)/index.html#essential-and-supplamentary-materials",
    "title": "Introduction to Mediation",
    "section": "Essential and Supplamentary Materials",
    "text": "Essential and Supplamentary Materials\n\n\n\n\n\n\nPrinciples and Practice of Structural Equation Modeling\nLongitudinal Structural Equation Modeling: A comprehensive Introduction\nOfficial lavaan tutorial from lavaan.org\nPsychometrics in Exercises using R and Rstudio by Prof Anna Brown\nIntroduction to Structural Equation Modeling (SEM) in R with lavaan by Dr Johnny Lin\n** And many other online resources that will be revealed in due time"
  },
  {
    "objectID": "posts/Introduction to Mediation (with lavaan)/index.html#todays-aims-in-terms-of-structural-equation-modeling-sem",
    "href": "posts/Introduction to Mediation (with lavaan)/index.html#todays-aims-in-terms-of-structural-equation-modeling-sem",
    "title": "Introduction to Mediation",
    "section": "Today’s Aims in Terms of Structural Equation Modeling (SEM)",
    "text": "Today’s Aims in Terms of Structural Equation Modeling (SEM)\n\nIntroduce key terminology that we will be using this term\nDiscuss examples of simple and multiple regression\nRevisit the same examples using lavaan\nDiscuss baximum likelihood vs. least squares"
  },
  {
    "objectID": "posts/Introduction to Mediation (with lavaan)/index.html#key-terminology",
    "href": "posts/Introduction to Mediation (with lavaan)/index.html#key-terminology",
    "title": "Introduction to Mediation",
    "section": "Key Terminology",
    "text": "Key Terminology\nWe will be using quite a few terms in our module so it is important to define them in advance and try to use them consistently. Most of the them are used as in the field but you could come across some slight variations in terminology. This should not put you off or scare you, as long as you understand the substance of each term. It is also a good idea to try to learn the visual equivalents of these terms"
  },
  {
    "objectID": "posts/Introduction to Mediation (with lavaan)/index.html#key-terminology-2",
    "href": "posts/Introduction to Mediation (with lavaan)/index.html#key-terminology-2",
    "title": "Introduction to Mediation",
    "section": "Key Terminology 2",
    "text": "Key Terminology 2\n\n\n\n\n\nlatent variable: a variable that is constructed/inferred indirectly by the data and does not exist in the data.\nobserved variable: a variable that has been measured and exists in our data.\nexogenous variable: an independent variable that explains an endogenous variable. Can be either observed \\((x)\\) or latent \\((ξ)\\).\nendogenous variable: a dependent variable that has a causal path leading to it. Can be either observed \\((y)\\) or latent \\((η)\\).\nmeasurement model: a model that links observed variables with latent variables"
  },
  {
    "objectID": "posts/Introduction to Mediation (with lavaan)/index.html#key-terminology-3",
    "href": "posts/Introduction to Mediation (with lavaan)/index.html#key-terminology-3",
    "title": "Introduction to Mediation",
    "section": "Key Terminology 3",
    "text": "Key Terminology 3\n\n\n\n\n\nindicator: an observed variable in a measurement model (can be exogenous or endogenous).\nfactor: a latent variable defined by its indicators (can be exogenous or endogenous).\nloading: a path between an indicator and a factor.\nstructural model: a model that specifies causal relationships among exogenous variables to endogenous variables (can be observed or latent).\nregression path: a path between exogenous and endogenous variables (can be observed or latent)."
  },
  {
    "objectID": "posts/Introduction to Mediation (with lavaan)/index.html#are-you-ready-for-the-first-headache-question",
    "href": "posts/Introduction to Mediation (with lavaan)/index.html#are-you-ready-for-the-first-headache-question",
    "title": "Introduction to Mediation",
    "section": "Are you ready for the first headache question?",
    "text": "Are you ready for the first headache question?\n\n\nCode\nplot_med &lt;- mark_sig(plot_med,model_med_fit)\nplot(plot_med)"
  },
  {
    "objectID": "posts/Introduction to Mediation (with lavaan)/index.html#let-us-expand-on-this-headache-a-bit-more",
    "href": "posts/Introduction to Mediation (with lavaan)/index.html#let-us-expand-on-this-headache-a-bit-more",
    "title": "Introduction to Mediation",
    "section": "Let us expand on this headache a bit more",
    "text": "Let us expand on this headache a bit more"
  },
  {
    "objectID": "posts/Introduction to Mediation (with lavaan)/index.html#simple-regression",
    "href": "posts/Introduction to Mediation (with lavaan)/index.html#simple-regression",
    "title": "Introduction to Mediation",
    "section": "Simple Regression",
    "text": "Simple Regression\nSo far we have learnt that a simple regression is the linear relation between a predictor (or an independent variable, or an observed exogenous variable) and an outcome (or observed endogenous variable).\n\\[\ny_1 = b_0 +b_1x_1 + ε_1\n\\]\nwhere \\(b_0\\) is the intercept and \\(b_1\\) is the coefficient of \\(x_1\\) (observed predictor) and \\(ε_1\\) is the residual with \\(y_1\\) being the outcome."
  },
  {
    "objectID": "posts/Introduction to Mediation (with lavaan)/index.html#simple-regression-cont.",
    "href": "posts/Introduction to Mediation (with lavaan)/index.html#simple-regression-cont.",
    "title": "Introduction to Mediation",
    "section": "Simple Regression cont.",
    "text": "Simple Regression cont.\nI strongly recommend reading Kline chapter 2, pages 25-30 at minimum, Regression Fundamentals.\n\\[\n\\hat{Y} = B_XX + A_X\n\\]\nThe above equation represents predicting Y from X\nAlso referred to as regressing Y on X, with \\(\\hat{Y}\\) representing predicted scores, \\(B_X\\) unstandardised regression coefficient for predictor \\(X\\), also known as slope, and \\(A_X\\) is the intercept.\nGenerally, with linear models we would use ordinary least square (OLS) so that the least squares criterion is satisfied. In practice, we are trying to minimise the sum of squared residuals, \\(\\sum(Y-\\hat{Y})\\)"
  },
  {
    "objectID": "posts/Introduction to Mediation (with lavaan)/index.html#let-us-see-an-example-with-data",
    "href": "posts/Introduction to Mediation (with lavaan)/index.html#let-us-see-an-example-with-data",
    "title": "Introduction to Mediation",
    "section": "Let us see an example with data",
    "text": "Let us see an example with data\nWe will work with the randomly generated data included in the random.csv\nThe datafile includes three variables:\nreading: reading ability as assessed in school\nincome: weekly family income in £\nbooks: number of books read in a month (on average)\nWe will create a simple regression model of reading  regressing on income using lm()"
  },
  {
    "objectID": "posts/Introduction to Mediation (with lavaan)/index.html#let-us-explore-an-example-with-data",
    "href": "posts/Introduction to Mediation (with lavaan)/index.html#let-us-explore-an-example-with-data",
    "title": "Introduction to Mediation",
    "section": "Let us explore an example with data",
    "text": "Let us explore an example with data\nFirst we will create some random data. As we mentioned last week, in this module we will be working exclusively with randomly generated data. Please note that it will also be required to generate random data for your assignments too.\n\n\nCode\nset.seed(13548) #note that we set the seed to a specific value\nX &lt;- rnorm(250) #number of observations\nM &lt;- 0.60*X + rnorm(250) # what does the 0.4 and rnorm represent here?\nY &lt;- 0.35*M +  rnorm(250) # what does the 0.6 and rnorm represent here?\n\ndf &lt;- data.frame(X=X, Y=Y, M=M)"
  },
  {
    "objectID": "posts/Introduction to Mediation (with lavaan)/index.html#we-will-now-specify-and-fit-a-path-analysis-model",
    "href": "posts/Introduction to Mediation (with lavaan)/index.html#we-will-now-specify-and-fit-a-path-analysis-model",
    "title": "Introduction to Mediation",
    "section": "We will now specify and fit a path analysis model",
    "text": "We will now specify and fit a path analysis model\n\n\nCode\nlibrary(lavaan) \nlibrary(semPlot)  \nmodel2_med &lt;- ' \n# alternative syntax of the model            \nY ~ c*X + b1*M1 + b2*M2           \nM1 ~ a1*X              \nM2 ~ a2*X     \n\n# indirect effects (a*b)              \na1b1 := a1*b1\na2b2 := a2*b2\n# total effect              \ntotal := c + (a1*b1) + (a2*b2)          \n' \nmodel2_med_fit &lt;- sem(model2_med, data = df, se = 'bootstrap', bootstrap = 1000)"
  },
  {
    "objectID": "posts/Introduction to Mediation (with lavaan)/index.html#exploring-the-model",
    "href": "posts/Introduction to Mediation (with lavaan)/index.html#exploring-the-model",
    "title": "Introduction to Mediation",
    "section": "Exploring the model",
    "text": "Exploring the model\n\n\nCode\nsummary(model_med_fit, fit.measures = TRUE, standardized = TRUE, rsquare = TRUE, ci = TRUE)\n\n\nlavaan 0.6.17 ended normally after 1 iteration\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         5\n\n  Number of observations                           250\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nModel Test Baseline Model:\n\n  Test statistic                               113.139\n  Degrees of freedom                                 3\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    1.000\n  Tucker-Lewis Index (TLI)                       1.000\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)               -712.004\n  Loglikelihood unrestricted model (H1)       -712.004\n                                                      \n  Akaike (AIC)                                1434.009\n  Bayesian (BIC)                              1451.616\n  Sample-size adjusted Bayesian (SABIC)       1435.766\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.000\n  90 Percent confidence interval - lower         0.000\n  90 Percent confidence interval - upper         0.000\n  P-value H_0: RMSEA &lt;= 0.050                       NA\n  P-value H_0: RMSEA &gt;= 0.080                       NA\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.000\n\nParameter Estimates:\n\n  Standard errors                            Bootstrap\n  Number of requested bootstrap draws             1000\n  Number of successful bootstrap draws            1000\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|) ci.lower ci.upper\n  Y ~                                                                   \n    X          (c)   -0.065    0.086   -0.762    0.446   -0.241    0.097\n  M ~                                                                   \n    X          (a)    0.611    0.066    9.219    0.000    0.475    0.737\n  Y ~                                                                   \n    M          (b)    0.381    0.068    5.604    0.000    0.248    0.517\n   Std.lv  Std.all\n                  \n   -0.065   -0.058\n                  \n    0.611    0.507\n                  \n    0.381    0.406\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|) ci.lower ci.upper\n   .Y                 1.018    0.086   11.783    0.000    0.839    1.185\n   .M                 1.002    0.083   12.063    0.000    0.843    1.175\n   Std.lv  Std.all\n    1.018    0.856\n    1.002    0.743\n\nR-Square:\n                   Estimate\n    Y                 0.144\n    M                 0.257\n\nDefined Parameters:\n                   Estimate  Std.Err  z-value  P(&gt;|z|) ci.lower ci.upper\n    ab                0.233    0.053    4.365    0.000    0.135    0.347\n    total             0.168    0.074    2.259    0.024    0.025    0.306\n   Std.lv  Std.all\n    0.233    0.206\n    0.168    0.148"
  },
  {
    "objectID": "posts/Introduction to Mediation (with lavaan)/index.html#first-we-will-investigate-the-three-simple-regressions",
    "href": "posts/Introduction to Mediation (with lavaan)/index.html#first-we-will-investigate-the-three-simple-regressions",
    "title": "Introduction to Mediation",
    "section": "First we will investigate the three simple regressions",
    "text": "First we will investigate the three simple regressions\n\n\nCode\nmodel_XY &lt;- lm(Y~X, data = df) # seen above as path c\nsummary(model_XY)\n\n\n\nCall:\nlm(formula = Y ~ X, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.5268 -0.7677 -0.0760  0.7206  3.5104 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)  0.03976    0.06851   0.580   0.5622  \nX            0.16775    0.07119   2.356   0.0192 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.083 on 248 degrees of freedom\nMultiple R-squared:  0.0219,    Adjusted R-squared:  0.01796 \nF-statistic: 5.553 on 1 and 248 DF,  p-value: 0.01923"
  },
  {
    "objectID": "posts/Introduction to Mediation (with lavaan)/index.html#first-we-will-investigate-the-three-simple-regressions-1",
    "href": "posts/Introduction to Mediation (with lavaan)/index.html#first-we-will-investigate-the-three-simple-regressions-1",
    "title": "Introduction to Mediation",
    "section": "First we will investigate the three simple regressions",
    "text": "First we will investigate the three simple regressions\n\n\nCode\nmodel_XM &lt;- lm(M~X, data = df) # seen above as path a \nsummary(model_XM)\n\n\n\nCall:\nlm(formula = M ~ X, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.1693 -0.7082  0.0269  0.6571  3.2536 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -0.00179    0.06358  -0.028    0.978    \nX            0.61127    0.06606   9.253   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.005 on 248 degrees of freedom\nMultiple R-squared:  0.2566,    Adjusted R-squared:  0.2536 \nF-statistic: 85.61 on 1 and 248 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "posts/Introduction to Mediation (with lavaan)/index.html#first-we-will-investigate-the-three-simple-regressions-2",
    "href": "posts/Introduction to Mediation (with lavaan)/index.html#first-we-will-investigate-the-three-simple-regressions-2",
    "title": "Introduction to Mediation",
    "section": "First we will investigate the three simple regressions",
    "text": "First we will investigate the three simple regressions\n\n\nCode\nmodel_MY &lt;- lm(Y~M, data = df) # seen above as path b  \nsummary(model_MY)\n\n\n\nCall:\nlm(formula = Y ~ M, data = df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.31772 -0.66815 -0.00959  0.65951  2.66509 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.03999    0.06416   0.623    0.534    \nM            0.35395    0.05525   6.406 7.46e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.015 on 248 degrees of freedom\nMultiple R-squared:  0.142, Adjusted R-squared:  0.1385 \nF-statistic: 41.03 on 1 and 248 DF,  p-value: 7.458e-10"
  },
  {
    "objectID": "posts/Introduction to Mediation (with lavaan)/index.html#first-we-will-investigate-path-c-regression",
    "href": "posts/Introduction to Mediation (with lavaan)/index.html#first-we-will-investigate-path-c-regression",
    "title": "Introduction to Mediation",
    "section": "First we will investigate path c regression",
    "text": "First we will investigate path c regression\n\n\nCode\nmodel_XY &lt;- lm(Y~X, data = df) # seen above as path c\nsummary(model_XY)\n\n\n\nCall:\nlm(formula = Y ~ X, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.5268 -0.7677 -0.0760  0.7206  3.5104 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)  0.03976    0.06851   0.580   0.5622  \nX            0.16775    0.07119   2.356   0.0192 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.083 on 248 degrees of freedom\nMultiple R-squared:  0.0219,    Adjusted R-squared:  0.01796 \nF-statistic: 5.553 on 1 and 248 DF,  p-value: 0.01923"
  },
  {
    "objectID": "posts/Introduction to Mediation (with lavaan)/index.html#path-a-regression",
    "href": "posts/Introduction to Mediation (with lavaan)/index.html#path-a-regression",
    "title": "Introduction to Mediation",
    "section": "Path a regression",
    "text": "Path a regression\n\n\nCode\nmodel_XM &lt;- lm(M~X, data = df) # seen above as path a \nsummary(model_XM)\n\n\n\nCall:\nlm(formula = M ~ X, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.1693 -0.7082  0.0269  0.6571  3.2536 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -0.00179    0.06358  -0.028    0.978    \nX            0.61127    0.06606   9.253   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.005 on 248 degrees of freedom\nMultiple R-squared:  0.2566,    Adjusted R-squared:  0.2536 \nF-statistic: 85.61 on 1 and 248 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "posts/Introduction to Mediation (with lavaan)/index.html#path-b-regression",
    "href": "posts/Introduction to Mediation (with lavaan)/index.html#path-b-regression",
    "title": "Introduction to Mediation",
    "section": "Path b regression",
    "text": "Path b regression\n\n\nCode\nmodel_MY &lt;- lm(Y~M, data = df) # seen above as path b  \nsummary(model_MY)\n\n\n\nCall:\nlm(formula = Y ~ M, data = df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.31772 -0.66815 -0.00959  0.65951  2.66509 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.03999    0.06416   0.623    0.534    \nM            0.35395    0.05525   6.406 7.46e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.015 on 248 degrees of freedom\nMultiple R-squared:  0.142, Adjusted R-squared:  0.1385 \nF-statistic: 41.03 on 1 and 248 DF,  p-value: 7.458e-10"
  },
  {
    "objectID": "posts/Introduction to Mediation (with lavaan)/index.html#visualising-the-path-analysis-mediation-model",
    "href": "posts/Introduction to Mediation (with lavaan)/index.html#visualising-the-path-analysis-mediation-model",
    "title": "Introduction to Mediation",
    "section": "Visualising the path analysis mediation model",
    "text": "Visualising the path analysis mediation model\n\n\nCode\nsemPaths(model_med_fit,\n         whatLabels = \"est\",\n         sizeMan = 10,          \n         style = \"ram\",          \n         layout = \"tree\",\n         intercepts = FALSE,\n         rotation = 2)"
  },
  {
    "objectID": "posts/Introduction to Mediation (with lavaan)/index.html#add-significance-stars",
    "href": "posts/Introduction to Mediation (with lavaan)/index.html#add-significance-stars",
    "title": "Introduction to Mediation",
    "section": "Add significance stars",
    "text": "Add significance stars\n\n\nCode\nlibrary(semptools)\nplot_med &lt;- semPaths(model_med_fit,\n         whatLabels = \"est\",\n         sizeMan = 10,          \n         style = \"ram\",          \n         layout = \"tree\",\n         intercepts = FALSE,\n         rotation = 2, edge.label.cex = 1)"
  },
  {
    "objectID": "posts/Introduction to Mediation (with lavaan)/index.html#how-can-we-interpret-the-above",
    "href": "posts/Introduction to Mediation (with lavaan)/index.html#how-can-we-interpret-the-above",
    "title": "Introduction to Mediation",
    "section": "How can we interpret the above?",
    "text": "How can we interpret the above?\nWe see that the paths a and b are significant. The same cannot be said for the path c. We also have a significant indirect effect and a significant total effect.\nIn this case our direct path c is no longer significant, hence this is a case of full mediation\nIf both the indirect path ab and the direct path c were significant this would have been a case of partial mediation.\nIf the indirect path was non-significant this would have been a case of no mediation."
  },
  {
    "objectID": "posts/Introduction to Mediation (with lavaan)/index.html#we-can-also-extract-confidence-intervals",
    "href": "posts/Introduction to Mediation (with lavaan)/index.html#we-can-also-extract-confidence-intervals",
    "title": "Introduction to Mediation",
    "section": "We can also extract confidence intervals",
    "text": "We can also extract confidence intervals\n\n\nCode\nlavaan::standardizedsolution(model_med_fit)\n\n\n    lhs op     rhs label est.std    se      z pvalue ci.lower ci.upper\n1     Y  ~       X     c  -0.058 0.076 -0.760  0.447   -0.207    0.091\n2     M  ~       X     a   0.507 0.043 11.678  0.000    0.422    0.592\n3     Y  ~       M     b   0.406 0.074  5.497  0.000    0.261    0.551\n4     Y ~~       Y         0.856 0.046 18.675  0.000    0.766    0.945\n5     M ~~       M         0.743 0.044 16.914  0.000    0.657    0.830\n6     X ~~       X         1.000 0.000     NA     NA    1.000    1.000\n7    ab :=     a*b    ab   0.206 0.045  4.573  0.000    0.118    0.294\n8 total := c+(a*b) total   0.148 0.064  2.315  0.021    0.023    0.273"
  },
  {
    "objectID": "posts/Introduction to Mediation (with lavaan)/index.html#how-do-we-report-it",
    "href": "posts/Introduction to Mediation (with lavaan)/index.html#how-do-we-report-it",
    "title": "Introduction to Mediation",
    "section": "How do we report it?",
    "text": "How do we report it?\nNote that the following is just a guideline and was written based on the standardized estimates.\n‘Initial analysis indicated that X significantly predicted M and Y, and M significantly predicted Y. However, when M was incorporated as a mediator in the X and Y relationship a full mediation occurred where the indirect effect was significant (b = 0.23, p &lt; .001, z = 4.57, se = 0.21, ci[0.95] = (0.12 - 0.29), the total effect was also significant (b = 0.17, p &lt; .021, z= 2.32, se = 0.06, ci(0.95) = [0.02 - 0.27]. The direct path of X predicting y was no longer significant (b = 0.06, p = .447, z= -0.76, se = 0.08, ci(0.95) = [-0.21 - 0.09]. Both paths a (X-&gt;M) and b (M-&gt;Y) were significant, (b = 0.51, p &lt; .001, z = 11.68, se = 0.04, ci[0.95] = (0.42 - 0.59) and (b = 0.41, p &lt; .001, z = 5.50, se = 0.07, ci[0.95] = (0.26 - 0.55) respectively. This was in line with our hypothesis that the relationship between X and Y can be entirely explained by changes in M.’"
  },
  {
    "objectID": "posts/Introduction to Mediation (with lavaan)/index.html#parameter-estimates",
    "href": "posts/Introduction to Mediation (with lavaan)/index.html#parameter-estimates",
    "title": "Introduction to Mediation",
    "section": "Parameter Estimates",
    "text": "Parameter Estimates\n\n\nCode\nparameterEstimates(model_med_fit, level = .95)\n\n\n    lhs op     rhs label    est    se      z pvalue ci.lower ci.upper\n1     Y  ~       X     c -0.065 0.086 -0.762  0.446   -0.241    0.097\n2     M  ~       X     a  0.611 0.066  9.219  0.000    0.475    0.737\n3     Y  ~       M     b  0.381 0.068  5.604  0.000    0.248    0.517\n4     Y ~~       Y        1.018 0.086 11.783  0.000    0.839    1.185\n5     M ~~       M        1.002 0.083 12.063  0.000    0.843    1.175\n6     X ~~       X        0.926 0.000     NA     NA    0.926    0.926\n7    ab :=     a*b    ab  0.233 0.053  4.365  0.000    0.135    0.347\n8 total := c+(a*b) total  0.168 0.074  2.259  0.024    0.025    0.306"
  },
  {
    "objectID": "posts/Introduction to Mediation (with lavaan)/index.html#standardised-parameter-estimates",
    "href": "posts/Introduction to Mediation (with lavaan)/index.html#standardised-parameter-estimates",
    "title": "Introduction to Mediation",
    "section": "Standardised Parameter Estimates",
    "text": "Standardised Parameter Estimates\n\n\nCode\nlavaan::standardizedsolution(model_med_fit, level = .95)\n\n\n    lhs op     rhs label est.std    se      z pvalue ci.lower ci.upper\n1     Y  ~       X     c  -0.058 0.076 -0.760  0.447   -0.207    0.091\n2     M  ~       X     a   0.507 0.043 11.678  0.000    0.422    0.592\n3     Y  ~       M     b   0.406 0.074  5.497  0.000    0.261    0.551\n4     Y ~~       Y         0.856 0.046 18.675  0.000    0.766    0.945\n5     M ~~       M         0.743 0.044 16.914  0.000    0.657    0.830\n6     X ~~       X         1.000 0.000     NA     NA    1.000    1.000\n7    ab :=     a*b    ab   0.206 0.045  4.573  0.000    0.118    0.294\n8 total := c+(a*b) total   0.148 0.064  2.315  0.021    0.023    0.273"
  },
  {
    "objectID": "posts/Introduction to Mediation (with lavaan)/index.html#we-will-now-apply-what-we-learnt-with-a-more-complex-example",
    "href": "posts/Introduction to Mediation (with lavaan)/index.html#we-will-now-apply-what-we-learnt-with-a-more-complex-example",
    "title": "Introduction to Mediation",
    "section": "We will now apply what we learnt with a more complex example",
    "text": "We will now apply what we learnt with a more complex example\nPlease log on to your Posit account and access the Week2 project where you can work on an example of serial mediation with 2 mediators."
  },
  {
    "objectID": "posts/Introduction to Mediation (with lavaan)/index.html#parallel-mediation",
    "href": "posts/Introduction to Mediation (with lavaan)/index.html#parallel-mediation",
    "title": "Introduction to Mediation",
    "section": "Parallel Mediation",
    "text": "Parallel Mediation"
  },
  {
    "objectID": "posts/Introduction to Mediation (with lavaan)/index.html#create-the-data",
    "href": "posts/Introduction to Mediation (with lavaan)/index.html#create-the-data",
    "title": "Introduction to Mediation",
    "section": "Create the data",
    "text": "Create the data\n\n\nCode\nset.seed(13548) #note that we set the seed to a specific value\nX &lt;- rnorm(250) #number of observations\nM1 &lt;- 0.60*X + rnorm(250)# what does the 0.4 and rnorm represent here?\nM2 &lt;- 0.50*X + rnorm(250)\nY &lt;- 0.35*M +  rnorm(250) # what does the 0.6 and rnorm represent here?\n\ndf &lt;- data.frame(X=X, Y=Y, M1=M1, M2=M2)"
  },
  {
    "objectID": "posts/Introduction to Mediation (with lavaan)/index.html#we-will-now-specify-and-fit-a-path-analysis-model-1",
    "href": "posts/Introduction to Mediation (with lavaan)/index.html#we-will-now-specify-and-fit-a-path-analysis-model-1",
    "title": "Introduction to Mediation",
    "section": "We will now specify and fit a path analysis model",
    "text": "We will now specify and fit a path analysis model\n\n\nCode\nlibrary(lavaan) \nlibrary(semPlot)  \nmodel2_med &lt;- ' \n# alternative syntax of the model            \nY ~ c*X + b1*M1 + b2*M2           \nM1 ~ a1*X              \nM2 ~ a2*X     \n\n# indirect effects (a*b)              \na1b1 := a1*b1\na2b2 := a2*b2\n# total effect              \ntotal := c + (a1*b1) + (a2*b2)          \n' \nmodel2_med_fit &lt;- sem(model2_med, data = df, se = 'bootstrap', bootstrap = 1000)"
  },
  {
    "objectID": "posts/Introduction to Mediation (with lavaan)/index.html#exploring-the-model-1",
    "href": "posts/Introduction to Mediation (with lavaan)/index.html#exploring-the-model-1",
    "title": "Introduction to Mediation",
    "section": "Exploring the model",
    "text": "Exploring the model\n\n\nCode\nsummary(model2_med_fit, fit.measures = TRUE, standardized = TRUE, rsquare = TRUE, ci = TRUE)\n\n\nlavaan 0.6.17 ended normally after 1 iteration\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         8\n\n  Number of observations                           250\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.243\n  Degrees of freedom                                 1\n  P-value (Chi-square)                           0.622\n\nModel Test Baseline Model:\n\n  Test statistic                               140.934\n  Degrees of freedom                                 6\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    1.000\n  Tucker-Lewis Index (TLI)                       1.034\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -1076.137\n  Loglikelihood unrestricted model (H1)      -1076.016\n                                                      \n  Akaike (AIC)                                2168.275\n  Bayesian (BIC)                              2196.446\n  Sample-size adjusted Bayesian (SABIC)       2171.086\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.000\n  90 Percent confidence interval - lower         0.000\n  90 Percent confidence interval - upper         0.132\n  P-value H_0: RMSEA &lt;= 0.050                    0.717\n  P-value H_0: RMSEA &gt;= 0.080                    0.181\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.008\n\nParameter Estimates:\n\n  Standard errors                            Bootstrap\n  Number of requested bootstrap draws             1000\n  Number of successful bootstrap draws            1000\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|) ci.lower ci.upper\n  Y ~                                                                   \n    X          (c)    0.003    0.090    0.035    0.972   -0.174    0.172\n    M1        (b1)    0.279    0.069    4.019    0.000    0.143    0.414\n    M2        (b2)    0.008    0.062    0.121    0.904   -0.113    0.132\n  M1 ~                                                                  \n    X         (a1)    0.611    0.063    9.718    0.000    0.477    0.731\n  M2 ~                                                                  \n    X         (a2)    0.454    0.067    6.736    0.000    0.320    0.593\n   Std.lv  Std.all\n                  \n    0.003    0.003\n    0.279    0.297\n    0.008    0.008\n                  \n    0.611    0.507\n                  \n    0.454    0.397\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|) ci.lower ci.upper\n   .Y                 1.077    0.093   11.551    0.000    0.885    1.248\n   .M1                1.002    0.083   12.104    0.000    0.831    1.156\n   .M2                1.019    0.086   11.887    0.000    0.852    1.184\n   Std.lv  Std.all\n    1.077    0.910\n    1.002    0.743\n    1.019    0.842\n\nR-Square:\n                   Estimate\n    Y                 0.090\n    M1                0.257\n    M2                0.158\n\nDefined Parameters:\n                   Estimate  Std.Err  z-value  P(&gt;|z|) ci.lower ci.upper\n    a1b1              0.170    0.045    3.815    0.000    0.086    0.259\n    a2b2              0.003    0.029    0.119    0.905   -0.052    0.062\n    total             0.177    0.079    2.227    0.026    0.011    0.336\n   Std.lv  Std.all\n    0.170    0.151\n    0.003    0.003\n    0.177    0.156"
  },
  {
    "objectID": "posts/Introduction to Mediation (with lavaan)/index.html#parameter-estimates-1",
    "href": "posts/Introduction to Mediation (with lavaan)/index.html#parameter-estimates-1",
    "title": "Introduction to Mediation",
    "section": "Parameter Estimates",
    "text": "Parameter Estimates\n\n\nCode\nparameterEstimates(model_med_fit, level = .95)\n\n\n    lhs op     rhs label    est    se      z pvalue ci.lower ci.upper\n1     Y  ~       X     c -0.065 0.086 -0.762  0.446   -0.241    0.097\n2     M  ~       X     a  0.611 0.066  9.219  0.000    0.475    0.737\n3     Y  ~       M     b  0.381 0.068  5.604  0.000    0.248    0.517\n4     Y ~~       Y        1.018 0.086 11.783  0.000    0.839    1.185\n5     M ~~       M        1.002 0.083 12.063  0.000    0.843    1.175\n6     X ~~       X        0.926 0.000     NA     NA    0.926    0.926\n7    ab :=     a*b    ab  0.233 0.053  4.365  0.000    0.135    0.347\n8 total := c+(a*b) total  0.168 0.074  2.259  0.024    0.025    0.306"
  },
  {
    "objectID": "posts/Introduction to Mediation (with lavaan)/index.html#visualisation-of-the-model",
    "href": "posts/Introduction to Mediation (with lavaan)/index.html#visualisation-of-the-model",
    "title": "Introduction to Mediation",
    "section": "Visualisation of the model",
    "text": "Visualisation of the model\n\n\nCode\nplot_med2 &lt;- semPaths(model2_med_fit,\n         whatLabels = \"est\",\n         sizeMan = 10,          \n         style = \"ram\",          \n         layout = \"tree\",\n         intercepts = FALSE,\n         rotation = 2, edge.label.cex = 1)"
  },
  {
    "objectID": "posts/Introduction to Mediation (with lavaan)/index.html#add-significance-stars-1",
    "href": "posts/Introduction to Mediation (with lavaan)/index.html#add-significance-stars-1",
    "title": "Introduction to Mediation",
    "section": "Add significance stars",
    "text": "Add significance stars\n\n\nCode\nplot_med2 &lt;- mark_sig(plot_med2,model2_med_fit)\nplot(plot_med2)"
  },
  {
    "objectID": "posts/Introduction to Mediation (with lavaan)/index.html#what-would-your-interpretation-be",
    "href": "posts/Introduction to Mediation (with lavaan)/index.html#what-would-your-interpretation-be",
    "title": "Introduction to Mediation",
    "section": "What would your interpretation be?",
    "text": "What would your interpretation be?"
  },
  {
    "objectID": "posts/Introduction to Mediation (with lavaan)/index.html#follow-up-topics",
    "href": "posts/Introduction to Mediation (with lavaan)/index.html#follow-up-topics",
    "title": "Introduction to Mediation",
    "section": "Follow-up topics",
    "text": "Follow-up topics\nThis Friday we are having our first Zoom session at 12 noon.\nThere we will be chatting about questions you might have but I also want you to explore 2 questions.\n\nHow can I add a variable in order to investigate for moderation effects between X and M?\nHow can I control for a specific variable in the simple mediation model? For example how can I control for the impact of age?"
  },
  {
    "objectID": "posts/Introduction to Advanced Statistics/index.html",
    "href": "posts/Introduction to Advanced Statistics/index.html",
    "title": "Introduction to Advanced Statistics",
    "section": "",
    "text": "This is me (used to be)\nI love my two boys\nI also love computer games, motorbikes, music, food\nFunnily enough I love maths and statistics, and even more teaching these\nI am also dyslexic so please do tell me when you spot typing mistakes, usually whole words missing."
  },
  {
    "objectID": "posts/Introduction to Mediation (with lavaan)/index.html#first-we-will-investigate-the-c-path-in-regression",
    "href": "posts/Introduction to Mediation (with lavaan)/index.html#first-we-will-investigate-the-c-path-in-regression",
    "title": "Introduction to Mediation",
    "section": "First we will investigate the c path in regression",
    "text": "First we will investigate the c path in regression\n\n\nCode\nmodel_XY &lt;- lm(Y~X, data = df) # seen above as path c\nsummary(model_XY)\n\n\n\nCall:\nlm(formula = Y ~ X, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.5268 -0.7677 -0.0760  0.7206  3.5104 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)  0.03976    0.06851   0.580   0.5622  \nX            0.16775    0.07119   2.356   0.0192 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.083 on 248 degrees of freedom\nMultiple R-squared:  0.0219,    Adjusted R-squared:  0.01796 \nF-statistic: 5.553 on 1 and 248 DF,  p-value: 0.01923"
  },
  {
    "objectID": "posts/Introduction to Mediation (with lavaan)/index.html#path-a-in-regression",
    "href": "posts/Introduction to Mediation (with lavaan)/index.html#path-a-in-regression",
    "title": "Introduction to Mediation",
    "section": "Path a in regression",
    "text": "Path a in regression\n\n\nCode\nmodel_XM &lt;- lm(M~X, data = df) # seen above as path a \nsummary(model_XM)\n\n\n\nCall:\nlm(formula = M ~ X, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.1693 -0.7082  0.0269  0.6571  3.2536 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -0.00179    0.06358  -0.028    0.978    \nX            0.61127    0.06606   9.253   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.005 on 248 degrees of freedom\nMultiple R-squared:  0.2566,    Adjusted R-squared:  0.2536 \nF-statistic: 85.61 on 1 and 248 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "posts/Introduction to Mediation (with lavaan)/index.html#path-b-in-regression",
    "href": "posts/Introduction to Mediation (with lavaan)/index.html#path-b-in-regression",
    "title": "Introduction to Mediation",
    "section": "Path b in regression",
    "text": "Path b in regression\n\n\nCode\nmodel_MY &lt;- lm(Y~M, data = df) # seen above as path b  \nsummary(model_MY)\n\n\n\nCall:\nlm(formula = Y ~ M, data = df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.31772 -0.66815 -0.00959  0.65951  2.66509 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.03999    0.06416   0.623    0.534    \nM            0.35395    0.05525   6.406 7.46e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.015 on 248 degrees of freedom\nMultiple R-squared:  0.142, Adjusted R-squared:  0.1385 \nF-statistic: 41.03 on 1 and 248 DF,  p-value: 7.458e-10"
  },
  {
    "objectID": "posts/Introduction to Mediation (with lavaan)/index.html#the-simple-mediation-model-visually-1",
    "href": "posts/Introduction to Mediation (with lavaan)/index.html#the-simple-mediation-model-visually-1",
    "title": "Introduction to Mediation",
    "section": "The Simple Mediation Model visually",
    "text": "The Simple Mediation Model visually"
  },
  {
    "objectID": "posts/Introduction to Mediation (with lavaan)/index.html#we-will-now-specify-and-fit-a-path-analysis-mediaton-model",
    "href": "posts/Introduction to Mediation (with lavaan)/index.html#we-will-now-specify-and-fit-a-path-analysis-mediaton-model",
    "title": "Introduction to Mediation",
    "section": "We will now specify and fit a path analysis mediaton model",
    "text": "We will now specify and fit a path analysis mediaton model\n\n\nCode\nlibrary(lavaan)\nlibrary(semPlot)\n\nmodel_med &lt;- ' # direct effect\n             Y ~ c*X\n           # mediator\n             M ~ a*X\n             Y ~ b*M\n           # indirect effect (a*b)\n             ab := a*b\n           # total effect\n             total := c + (a*b)\n         '\nmodel_med_fit &lt;- sem(model_med, data = df, se = 'bootstrap', bootstrap = 1000, )"
  },
  {
    "objectID": "posts/Introduction to Mediation (with lavaan)/index.html#guidelines-prior-to-carry-out-mediation-analysis-1",
    "href": "posts/Introduction to Mediation (with lavaan)/index.html#guidelines-prior-to-carry-out-mediation-analysis-1",
    "title": "Introduction to Mediation",
    "section": "Guidelines prior to carry out mediation analysis",
    "text": "Guidelines prior to carry out mediation analysis\n\n\n\n\n\nmodel_med &lt;- ' # direct effect\n             Y ~ c*X\n           # mediator\n             M ~ a*X\n             Y ~ b*M\n           # indirect effect (a*b)\n             ab := a*b\n           # total effect\n             total := c + (a*b)\n         '"
  },
  {
    "objectID": "posts/Assignment 1/index.html",
    "href": "posts/Assignment 1/index.html",
    "title": "Assignment 1",
    "section": "",
    "text": "The following is a template of a study design where we randomly generated data to test our code. Once you run the code it will generate 5 variables, X, M1, M2, M3, and Y. Where X is our independent variable, M1, M2, M3 the three mediators, and Y our outcome. Feel free to rename the variables in this assignment but do not change the code that generates the data in terms of numbers (You will see that further down in this text).\nFor the purposes of this assignment we will treat the randomly generated data as if they were the real data. We hypothesise that our predictor X is fully mediated by a combination of serial and parallel mediations, where M1 and M2 mediate in sequence and M3 in parallel with M1 and M2. You can see this in the diagram below."
  },
  {
    "objectID": "posts/Assignment 1/index.html#study-design",
    "href": "posts/Assignment 1/index.html#study-design",
    "title": "Assignment 1",
    "section": "",
    "text": "The following is a template of a study design where we randomly generated data to test our code. Once you run the code it will generate 5 variables, X, M1, M2, M3, and Y. Where X is our independent variable, M1, M2, M3 the three mediators, and Y our outcome. Feel free to rename the variables in this assignment but do not change the code that generates the data in terms of numbers (You will see that further down in this text).\nFor the purposes of this assignment we will treat the randomly generated data as if they were the real data. We hypothesise that our predictor X is fully mediated by a combination of serial and parallel mediations, where M1 and M2 mediate in sequence and M3 in parallel with M1 and M2. You can see this in the diagram below."
  },
  {
    "objectID": "posts/Assignment 1/index.html#assignment",
    "href": "posts/Assignment 1/index.html#assignment",
    "title": "Assignment 1",
    "section": "Assignment",
    "text": "Assignment\nWrite the appropriate code that will model the above hypothesis in lavaan and run all required analyses. As we discussed in our workshop there are specific steps that need to be followed before we even run a mediation model. Make sure that you have followed all these steps prior to running a mediation analysis. Following your analysis evaluate whether our hypothesis can be supported, if not suggest and test a more appropriate model. Make sure to offer a justification on the course you chose to follow. This is the point where you can demonstrate a deeper understanding of mediation analysis and critical thinking will allow you to receive higher grades. You should complete your assignment in a quarto file, render it and save as a pdf. You should then upload that pdf file in Canvas. The deadline for this report is Tuesday 13th of February at 4pm."
  },
  {
    "objectID": "posts/Assignment 1/index.html#marking-criteria",
    "href": "posts/Assignment 1/index.html#marking-criteria",
    "title": "Assignment 1",
    "section": "Marking criteria",
    "text": "Marking criteria\nYour work will be evaluated based on the following criteria\n\nCorrect statistical analyses including descriptive statistics and linear models\nReporting all statistical figures according to the APA 7 guidelines\nYou should include at minimum one table and one graph, however more may be required based on the need for a follow up analysis\nYour writing should be clear and concise, try to avoid repetitive statements.\nAs an exception and purely for assessment purposes we expect you to report the mediation analyses both in text and in tables."
  },
  {
    "objectID": "posts/Assignment 1/index.html#generating-the-data",
    "href": "posts/Assignment 1/index.html#generating-the-data",
    "title": "Assignment 1",
    "section": "Generating the data",
    "text": "Generating the data\nMake sure to run the following code snipet as is in terms of numbers, any alterations may lead to errors and you will be marked down. You can however rename the variables (for example instead of X you may choose to declare Anxiety etc)\n\nset.seed(22335) #\nX &lt;- rnorm(250) \nM1 &lt;- 0.60*X + rnorm(250) \nM2 &lt;- 0.35*X + rnorm(250)\nM3 &lt;- 0.55*X + rnorm(250)\nY &lt;- 0.35*M1 + 0.1*M2 + 0.33*M3 + rnorm(250) \n\ndf &lt;- data.frame(X=X, M1=M1, M2=M2, M3=M3, Y=Y)"
  },
  {
    "objectID": "posts/Introduction to S.E.M/index.html#todays-aims",
    "href": "posts/Introduction to S.E.M/index.html#todays-aims",
    "title": "Introduction to S.E.M",
    "section": "Today’s Aims",
    "text": "Today’s Aims\nToday we will use Specification of observed variable models (Path) as means to introduce S.E.M.\nOverall, today’s session will be theoretical but we will also use coding to apply what will be discussed."
  },
  {
    "objectID": "posts/Introduction to S.E.M/index.html#steps-of-sem",
    "href": "posts/Introduction to S.E.M/index.html#steps-of-sem",
    "title": "Introduction to S.E.M.",
    "section": "Steps of SEM",
    "text": "Steps of SEM"
  },
  {
    "objectID": "posts/Introduction to S.E.M/index.html#basic-steps",
    "href": "posts/Introduction to S.E.M/index.html#basic-steps",
    "title": "Introduction to S.E.M",
    "section": "Basic Steps",
    "text": "Basic Steps\n\nBasic steps to SEM as proposed by Kline, page 118"
  },
  {
    "objectID": "posts/Introduction to S.E.M/index.html#specification",
    "href": "posts/Introduction to S.E.M/index.html#specification",
    "title": "Introduction to S.E.M",
    "section": "Specification",
    "text": "Specification\nSpecifying the model is probably the most important step in the process as it is assumed that the hypothesis, hence the model, is valid and correct.\nKline also suggests that alternative possible models could also be noted as potential models should they be justified by theory or data findings."
  },
  {
    "objectID": "posts/Introduction to S.E.M/index.html#identification",
    "href": "posts/Introduction to S.E.M/index.html#identification",
    "title": "Introduction to S.E.M",
    "section": "Identification",
    "text": "Identification\nSpecification of a model is usually a conceptual starting point and regardless of how well a model is grounded in theory, there will always be the need to be supported by statistical findings.\nWe therefore, build statistical models comprised of equations that define model parameters. These statistical parameters set and test relationships between our variables.\nA statistical model must be identified, meaning it is theoretically possible to algorithmically aarrive to a unique solution for each of the model parameters.\nImportant: Identification occurs regardless of our data and is a property of the model."
  },
  {
    "objectID": "posts/Introduction to S.E.M/index.html#an-oversimplified-example",
    "href": "posts/Introduction to S.E.M/index.html#an-oversimplified-example",
    "title": "Introduction to S.E.M",
    "section": "An oversimplified example",
    "text": "An oversimplified example\nIn school you might have come across the following simple example\n\\[\n3x + 4y =10\n\\]\n\\[\nx-y=1\n\\]\nThis is an example where we have two sources of information, in this case two equations, and we need to infer two unknown parameters, \\(x\\) and \\(y\\)."
  },
  {
    "objectID": "posts/Introduction to S.E.M/index.html#model-identification",
    "href": "posts/Introduction to S.E.M/index.html#model-identification",
    "title": "Introduction to S.E.M",
    "section": "Model Identification",
    "text": "Model Identification\n\nWhen the number of parameters specified in our model is equal to the number of unique sources of information then we have df = 0 and a just-identified model.\nWhen the number of parameters specified in our model is less than the number of unique sources of information then we have df &gt; 0 and an over-identified model.\nWhen the number of parameters specified in our model is greater then the number of unique sources of information then we have df &lt; 0 and an under-identified model.\n\ndf = number of unique sources of information - number of parameters specified"
  },
  {
    "objectID": "posts/Introduction to S.E.M/index.html#a-visual-example",
    "href": "posts/Introduction to S.E.M/index.html#a-visual-example",
    "title": "Introduction to S.E.M",
    "section": "A visual example",
    "text": "A visual example"
  },
  {
    "objectID": "posts/Introduction to S.E.M/index.html#model-identification-of-our-example",
    "href": "posts/Introduction to S.E.M/index.html#model-identification-of-our-example",
    "title": "Introduction to S.E.M",
    "section": "Model identification of our example",
    "text": "Model identification of our example\nWe have 5 variables so this is equivalent to 15 unique sources of information. You can visualise this if you imagine a triangular correlation matrix.\n\nTo make your life easier you can use this formula,\n\\(p*(p+1)/2\\)\nWhere \\(p\\) is the number of variables in your model."
  },
  {
    "objectID": "posts/Introduction to S.E.M/index.html#select-measures-and-collect-data",
    "href": "posts/Introduction to S.E.M/index.html#select-measures-and-collect-data",
    "title": "Introduction to S.E.M",
    "section": "Select measures and collect data",
    "text": "Select measures and collect data\nYour confidence in your statistical findings of your model will only be as good as your measurements and the quality of your data collection.\nIt is therefore vital to select good measures and follow solid methodological guidelines in terms of data collection and data analysis."
  },
  {
    "objectID": "posts/Introduction to S.E.M/index.html#estimation",
    "href": "posts/Introduction to S.E.M/index.html#estimation",
    "title": "Introduction to S.E.M",
    "section": "Estimation",
    "text": "Estimation\nUse of statistical software to carry out the SEM analysis and go through a cycle of the following steps:\n\nEvaluate model fit (only when df &gt; 0)\n\nChi-square Test \\((x^2)\\)\nComparative Fit Index (CFI)\nTucker-Lewis Index (TLI)\nRoot Mean Square Error of Approximation (RMSEA)\nStandardized Root Mean Square Residual (SRMR)"
  },
  {
    "objectID": "posts/Introduction to S.E.M/index.html#parameters-to-estimate",
    "href": "posts/Introduction to S.E.M/index.html#parameters-to-estimate",
    "title": "Introduction to S.E.M",
    "section": "Parameters to Estimate",
    "text": "Parameters to Estimate\n\nBeware of software default settings. You may not necessarily request an estimate but the software might calculate it by default. For example, the residual errors."
  },
  {
    "objectID": "posts/Introduction to S.E.M/index.html#model-identification-1",
    "href": "posts/Introduction to S.E.M/index.html#model-identification-1",
    "title": "Introduction to S.E.M",
    "section": "Model Identification",
    "text": "Model Identification\n15 unique sources of information - 12 parameters to estimate = 3 (df = 3)\nTherefore, this is an over-identified model!"
  },
  {
    "objectID": "posts/Introduction to S.E.M/index.html#chi-square-test-x2",
    "href": "posts/Introduction to S.E.M/index.html#chi-square-test-x2",
    "title": "Introduction to S.E.M",
    "section": "Chi-square Test \\((x^2)\\)",
    "text": "Chi-square Test \\((x^2)\\)\nThe chi-square test assesses whether our model fits the data with \\(p &lt; .05\\) indicating that the model does not fit the data well. Be aware of this as many students are fixated to significant p-values!\nAlso, as you might have heard multiple times before, this test is sensitive to sample size and does not behave well with non-normal distributions!"
  },
  {
    "objectID": "posts/Introduction to S.E.M/index.html#comparative-fit-index-cfi",
    "href": "posts/Introduction to S.E.M/index.html#comparative-fit-index-cfi",
    "title": "Introduction to S.E.M",
    "section": "Comparative Fit Index, CFI",
    "text": "Comparative Fit Index, CFI\nThis fit index is, as the naming strongly implies, a comparative fit index. This means it compares our current model to a baseline model, typically a null or empty model.\nWe tend to regard CFI values above .90 as good fit index for our model.\nCFI behaves better than the chi-square test with regards to sample size."
  },
  {
    "objectID": "posts/Introduction to S.E.M/index.html#tucker-lewis-index-tli",
    "href": "posts/Introduction to S.E.M/index.html#tucker-lewis-index-tli",
    "title": "Introduction to S.E.M",
    "section": "Tucker-Lewis Index (TLI)",
    "text": "Tucker-Lewis Index (TLI)\nAgain a comparative fit index where we compare our model to a null or empty model.\nIt is also, a better fit index compared to CFI when we have small sample sizes.\nWe tend to regard TLI values equal or greater than .95 as good fit index for our model, with .90 being considered as the absolute lowest acceptable value."
  },
  {
    "objectID": "posts/Introduction to S.E.M/index.html#root-mean-square-error-of-approximation-rmsea",
    "href": "posts/Introduction to S.E.M/index.html#root-mean-square-error-of-approximation-rmsea",
    "title": "Introduction to S.E.M",
    "section": "Root Mean Square Error of Approximation (RMSEA)",
    "text": "Root Mean Square Error of Approximation (RMSEA)\nContrary to the previous two, RMSEA is an absolute fit index.\nIt strongly favours more parsimonious models and heavily penalizes more complex models (keep that in mind).\nWe tend to regard RMSEA values equal or less than .08 as good fit index for our model, with .10 being considered as the absolute highest acceptable value.\nHeadache question: How would you expect the RMSEA value to behave in relation to df?"
  },
  {
    "objectID": "posts/Introduction to S.E.M/index.html#standardized-root-mean-square-residual-srmr",
    "href": "posts/Introduction to S.E.M/index.html#standardized-root-mean-square-residual-srmr",
    "title": "Introduction to S.E.M",
    "section": "Standardized Root Mean Square Residual (SRMR)",
    "text": "Standardized Root Mean Square Residual (SRMR)\nAlso an absolute fit index, with values less or equal to .08 indicating good fit."
  },
  {
    "objectID": "posts/Introduction to S.E.M/index.html#some-good-news-and-some-bad-news",
    "href": "posts/Introduction to S.E.M/index.html#some-good-news-and-some-bad-news",
    "title": "Introduction to S.E.M",
    "section": "Some good news and some bad news",
    "text": "Some good news and some bad news\nVery often you will have fit indices that contradict each other, for example CFI and TLI may be pointing towards good fit whereas RMSEA and SRMR may be pointing towards the opposite direction. What should you do?\nHowever, if all of the fit indices are saying that you do not have a good model fit then you should not proceed to interpret model parameters!\nInstead you should …"
  },
  {
    "objectID": "posts/Introduction to S.E.M/index.html#instead-you-should",
    "href": "posts/Introduction to S.E.M/index.html#instead-you-should",
    "title": "Introduction to S.E.M",
    "section": "Instead you should …",
    "text": "Instead you should …"
  },
  {
    "objectID": "posts/Introduction to S.E.M/index.html#respecify-or-report-results",
    "href": "posts/Introduction to S.E.M/index.html#respecify-or-report-results",
    "title": "Introduction to S.E.M",
    "section": "Respecify or report results?",
    "text": "Respecify or report results?\nKind of both. Report your initial results and if you have a solid justification of why you could respecify then go ahead and respecify. If you do not have that solid reasoning then mention that and finish with reporting the inadequate model fit!"
  },
  {
    "objectID": "posts/Introduction to S.E.M/index.html#my-model-fit-is-good",
    "href": "posts/Introduction to S.E.M/index.html#my-model-fit-is-good",
    "title": "Introduction to S.E.M",
    "section": "My model fit is good",
    "text": "My model fit is good\nMy model fit indices indicated a good fit, should I just report my findings?\nKline suggests that researchers should also consider equivalent or near-equivalent models, demonstrating that their initial model is a better model than the near equivalent ones.\nIt will very often be the case that these models may have better fit than the initial model so it is the researcher’s duty to argue why these need to be rejected at the expense of the proposed model!"
  },
  {
    "objectID": "posts/Introduction to S.E.M/index.html#reporting-sem-analysis",
    "href": "posts/Introduction to S.E.M/index.html#reporting-sem-analysis",
    "title": "Introduction to S.E.M",
    "section": "Reporting SEM analysis",
    "text": "Reporting SEM analysis\nIt is vital that all analyses steps are fully disclosed and all statistical figures are accurately reported. It should also be explicitly stated how all the above steps were taken and how the proposed initial/final model is a better model compared to equivalent ones!"
  },
  {
    "objectID": "posts/Introduction to S.E.M/index.html#follow-up-reading",
    "href": "posts/Introduction to S.E.M/index.html#follow-up-reading",
    "title": "Introduction to S.E.M",
    "section": "Follow-up reading",
    "text": "Follow-up reading\nI strongly advise you to finish reading chapter 6, pages 117 to 142, Principles and Practice of Structural Equation Modeling, Fourth Edition."
  },
  {
    "objectID": "posts/Exploratory Factor Analysis/index.html#todays-aims",
    "href": "posts/Exploratory Factor Analysis/index.html#todays-aims",
    "title": "Exploratory Factor Analysis",
    "section": "Today’s Aims",
    "text": "Today’s Aims\nToday we will define what exploratory factor analysis (EFA) is, we focus on the steps required to carry out EFA using R."
  },
  {
    "objectID": "posts/Exploratory Factor Analysis/index.html#what-is-factor-analysis",
    "href": "posts/Exploratory Factor Analysis/index.html#what-is-factor-analysis",
    "title": "Exploratory Factor Analysis",
    "section": "What is Factor Analysis",
    "text": "What is Factor Analysis\nFactor Analysis in the statistical technique that seeks to identify underlying relationships between observed variables.\nSpecifically, grouping these variables into groups where in-group variables correlate highly.\nIdeally, we want variables to correlate highly only with their in-group variables, and correlate weakly or not at all with variables belonging to other groups.\nWe will be referring to the term group as factor. There factors are unobserved variables…"
  },
  {
    "objectID": "posts/Exploratory Factor Analysis/index.html#what-is-exploratory-factor-analysis",
    "href": "posts/Exploratory Factor Analysis/index.html#what-is-exploratory-factor-analysis",
    "title": "Exploratory Factor Analysis",
    "section": "What is Exploratory Factor Analysis?",
    "text": "What is Exploratory Factor Analysis?\nIt is a statistical exploratory process that seeks to identify underlying relationships between observed variables.\nFurthermore, with EFA we aim to identify latent variables that might are responsible for the shared variances between the observed variables. As mentioned in our introduction lectures latent variables are variables that are not directly measured. Instead, they are inferred by the existing relationships between our observed variables."
  },
  {
    "objectID": "posts/Exploratory Factor Analysis/index.html#specification-of-models-in-efa",
    "href": "posts/Exploratory Factor Analysis/index.html#specification-of-models-in-efa",
    "title": "Exploratory Factor Analysis",
    "section": "Specification of models in EFA",
    "text": "Specification of models in EFA\nAccording to Kline (pages 190-191):\n\nEFA does not require an a priori specification, with number of possible factors varying from one up to as many as the indicators. (Highly not advised, but theoretically possible)\nIn EFA we have unrestricted measurement models where indicators are allowed to depend on all factors\nMultiple factors models in EFA are not actually identified. Headache question: Why would that be the case?\nIn EFA we assume that specific variance of each indicator is not shared what that of any other indicator\n\nNote: Next week we will contrast all the above points with Confirmatory Factor Analysis (CFA)"
  },
  {
    "objectID": "posts/Exploratory Factor Analysis/index.html#visualisation",
    "href": "posts/Exploratory Factor Analysis/index.html#visualisation",
    "title": "Exploratory Factor Analysis",
    "section": "Visualisation",
    "text": "Visualisation"
  },
  {
    "objectID": "posts/Exploratory Factor Analysis/index.html#do-we-analyze-correlated-factors",
    "href": "posts/Exploratory Factor Analysis/index.html#do-we-analyze-correlated-factors",
    "title": "Exploratory Factor Analysis",
    "section": "Do we analyze correlated Factors?",
    "text": "Do we analyze correlated Factors?\nTypically this is not required. However, we can specify a rotation that will allow us to analyze correlated factors!\nRotation?\nRotation allows us to simplify our model further, thus enhance its interpretation. This is an option that is applied after our initial solution and its aim is to achieve a solution where an indicator has high loading to one factor (or as few as possible) and low loading on all other factors."
  },
  {
    "objectID": "posts/Exploratory Factor Analysis/index.html#rotations",
    "href": "posts/Exploratory Factor Analysis/index.html#rotations",
    "title": "Exploratory Factor Analysis",
    "section": "Rotations",
    "text": "Rotations\n\nOrthogonal rotation, usually the default setting for most EFA functions, treats all factors are non-correlated. The most commonly used is Varimax, however there are others. Be cautious when using orthogonal rotations, refer back to your theoretical background in order to make sure that your possible factors are indeed expected to be uncorrelated.\nOblique rotation, allows for correlated factors. The most commonly used is Promax, however there are others.\n\nSo which one should we use? Outside of the correlated or uncorrelated allowance it is difficult to decide. Many different rotation methods may give similarly valid results. I advise you to look into the factor score indeterminacy for more details."
  },
  {
    "objectID": "posts/Exploratory Factor Analysis/index.html#software-considerations",
    "href": "posts/Exploratory Factor Analysis/index.html#software-considerations",
    "title": "Exploratory Factor Analysis",
    "section": "Software Considerations",
    "text": "Software Considerations\nCan we use lavaan to carry our EFA?\nYes, however …… psych package might make your life easier.\nEFAtools, will definitely make your life easier.\nWe will use all three in combination in the coming examples and you can decide on your own."
  },
  {
    "objectID": "posts/Exploratory Factor Analysis/index.html#can-we-always-carry-out-efa",
    "href": "posts/Exploratory Factor Analysis/index.html#can-we-always-carry-out-efa",
    "title": "Exploratory Factor Analysis",
    "section": "Can we always carry out EFA?",
    "text": "Can we always carry out EFA?\nSome researchers argue that you could. You can definitely try, in terms of coding and running the relevant software.\nHowever, you shouldn’t if you do not meet the following two criteria (at minimum).\nKMO: Kaiser-Meyer-Olkin measure of sampling adequacy: Evaluates whether our sample is suitable for factor analysis.It does so by evaluating the proportion of variance among variable that could be attributed to underlying factors. Ranges from 0 - 1, and values closer to 1 indicate higher suitability.\nBartlett’s test of Sphericity: Assesses whether our variables/indicators have significant correlations. If our correlations are non-significant then we should not proceed. Here we are looking for evidence (p &lt; .05) in order to reject the null hypothesis that our inter-variable correlations are zero."
  },
  {
    "objectID": "posts/Exploratory Factor Analysis/index.html#other-useful-terminology",
    "href": "posts/Exploratory Factor Analysis/index.html#other-useful-terminology",
    "title": "Exploratory Factor Analysis",
    "section": "Other Useful Terminology",
    "text": "Other Useful Terminology\n\nCommunality: The proportion of variance explained by the common factor. This will be used as a decision criterion to include or exclude indicators to a factor.\nPercentage of Variance: The percentage of variance that is due to one factor in relation to the total variance in all factors.\nEigenvalue: The total variance explained by each factor, we are ideally looking for eigenvalues above 1."
  },
  {
    "objectID": "posts/Exploratory Factor Analysis/index.html#let-us-work-through-an-example-together",
    "href": "posts/Exploratory Factor Analysis/index.html#let-us-work-through-an-example-together",
    "title": "Exploratory Factor Analysis",
    "section": "Let us work through an example together",
    "text": "Let us work through an example together\nFirst, let’s create the random data.\n\n\nCode\nset.seed(1212)\n### normally distributed factors\n### these are just to help me set the indicators\n### the f1 and f2 will not be included in the data.frame\nf1 &lt;- rnorm(250)\nf2 &lt;- rnorm(250)\n\n### f1 indicators x1 to x3\nx1 &lt;- f1 + rnorm(250, sd=0.15)\nx2 &lt;- f1 + rnorm(250, sd=0.15)\nx3 &lt;- f1 + rnorm(250, sd=0.15)\n\n### f2 indicators x4 to x6\nx4 &lt;- f2 + rnorm(250, sd=0.15)\nx5 &lt;- f2 + rnorm(250, sd=0.15)\nx6 &lt;- f2 + rnorm(250, sd=0.15)\n\n### creating the dataframe\ndf &lt;- data.frame(x1=x1, x2=x2, x3=x3, x4=x4, x5=x5, x6=x6)"
  },
  {
    "objectID": "posts/Exploratory Factor Analysis/index.html#assess-kmo-and-bartletts-test-of-sphericity",
    "href": "posts/Exploratory Factor Analysis/index.html#assess-kmo-and-bartletts-test-of-sphericity",
    "title": "Exploratory Factor Analysis",
    "section": "Assess KMO and Bartlett’s test of Sphericity",
    "text": "Assess KMO and Bartlett’s test of Sphericity\nEFAtools\n\n\nCode\nlibrary(psych)\nlibrary(EFAtools)\n\nKMO(df) ### THIS IS NOW MASKED BY EFAtools\n\n\n\n── Kaiser-Meyer-Olkin criterion (KMO) ──────────────────────────────────────────\n\n✔ The overall KMO value for your data is middling.\n  These data are probably suitable for factor analysis.\n\n  Overall: 0.795\n\n  For each variable:\n   x1    x2    x3    x4    x5    x6 \n0.790 0.775 0.819 0.789 0.793 0.807 \n\n\nCode\nBARTLETT(df) ### THIS IS NOW MASKED BY EFAtools\n\n\n\n✔ The Bartlett's test of sphericity was significant at an alpha level of .05.\n  These data are probably suitable for factor analysis.\n\n  𝜒²(15) = 3272.23, p &lt; .001"
  },
  {
    "objectID": "posts/Exploratory Factor Analysis/index.html#assess-kmo-and-bartletts-test-of-sphericity-1",
    "href": "posts/Exploratory Factor Analysis/index.html#assess-kmo-and-bartletts-test-of-sphericity-1",
    "title": "Exploratory Factor Analysis",
    "section": "Assess KMO and Bartlett’s test of Sphericity",
    "text": "Assess KMO and Bartlett’s test of Sphericity\npsych\n\n\nCode\npsych::KMO(df)\n\n\nKaiser-Meyer-Olkin factor adequacy\nCall: psych::KMO(r = df)\nOverall MSA =  0.8\nMSA for each item = \n  x1   x2   x3   x4   x5   x6 \n0.79 0.77 0.82 0.79 0.79 0.81 \n\n\nCode\nr &lt;- cor(df)\npsych::cortest.bartlett(r)\n\n\n$chisq\n[1] 1278.319\n\n$p.value\n[1] 2.428264e-263\n\n$df\n[1] 15"
  },
  {
    "objectID": "posts/Exploratory Factor Analysis/index.html#determining-number-of-factors",
    "href": "posts/Exploratory Factor Analysis/index.html#determining-number-of-factors",
    "title": "Exploratory Factor Analysis",
    "section": "Determining number of factors",
    "text": "Determining number of factors\nEFAtools\n\n\nCode\nPARALLEL(df, eigen_type = \"PCA\")\n\n\nParallel Analysis performed using 1000 simulated random data sets\nEigenvalues were found using PCA\n\nDecision rule used: means\n\n── Number of factors to retain according to ────────────────────────────────────\n\n◌ PCA-determined eigenvalues:  2"
  },
  {
    "objectID": "posts/Exploratory Factor Analysis/index.html#determining-number-of-factors-1",
    "href": "posts/Exploratory Factor Analysis/index.html#determining-number-of-factors-1",
    "title": "Exploratory Factor Analysis",
    "section": "Determining number of factors",
    "text": "Determining number of factors\npsych\n\n\nCode\nfa.parallel(df, fa=\"pc\")\n\n\n\nParallel analysis suggests that the number of factors =  NA  and the number of components =  2"
  },
  {
    "objectID": "posts/Exploratory Factor Analysis/index.html#in-efatools-you-can-also-run-multiple-retention-methods",
    "href": "posts/Exploratory Factor Analysis/index.html#in-efatools-you-can-also-run-multiple-retention-methods",
    "title": "Exploratory Factor Analysis",
    "section": "In EFAtools you can also run multiple retention methods",
    "text": "In EFAtools you can also run multiple retention methods\n\n\nCode\nN_FACTORS(df, criteria = c(\"PARALLEL\", \"EKC\", \"SMT\"),\n          eigen_type_other = c(\"SMC\", \"PCA\"))\n\n\n\n                                                                                                                                                                \n  🏃 ◯ ◯ Running EKC\n                                                                                                                                                                \n ◉ 🏃 ◯ Running PARALLEL\n                                                                                                                                                                \n ◉ ◉ 🏃  Running SMT\n                                                                                                                                                                \n ◉ ◉ ◉ Done!\n\n\n\n── Tests for the suitability of the data for factor analysis ───────────────────\n\nBartlett's test of sphericity\n\n✔ The Bartlett's test of sphericity was significant at an alpha level of .05.\n  These data are probably suitable for factor analysis.\n\n  𝜒²(15) = 3272.23, p &lt; .001\n\nKaiser-Meyer-Olkin criterion (KMO)\n\n✔ The overall KMO value for your data is middling with 0.795.\n  These data are probably suitable for factor analysis.\n\n── Number of factors suggested by the different factor retention criteria ──────\n\n◌ Empirical Kaiser criterion: 2\n◌ Parallel analysis with PCA: 2\n◌ Parallel analysis with SMC: 2\n◌ Sequential 𝜒² model tests: 2\n◌ Lower bound of RMSEA 90% confidence interval: 2\n◌ Akaike Information Criterion: 2"
  },
  {
    "objectID": "posts/Exploratory Factor Analysis/index.html#multiple-scree-plots",
    "href": "posts/Exploratory Factor Analysis/index.html#multiple-scree-plots",
    "title": "Exploratory Factor Analysis",
    "section": "Multiple Scree-plots",
    "text": "Multiple Scree-plots\nTry the following code at home by removing the #\n\n\nCode\n# N_FACTORS(df, method = \"ULS\")"
  },
  {
    "objectID": "posts/Exploratory Factor Analysis/index.html#factor-extraction",
    "href": "posts/Exploratory Factor Analysis/index.html#factor-extraction",
    "title": "Exploratory Factor Analysis",
    "section": "Factor Extraction",
    "text": "Factor Extraction\nEFAtools\n\n\nCode\nEFA(df, n_factors = 2, method = \"ML\")\n\n\n\nEFA performed with type = 'EFAtools', method = 'ML', and rotation = 'none'.\n\n── Unrotated Loadings ──────────────────────────────────────────────────────────\n\n     F1      F2  \nx1  -.561    .815\nx2  -.562    .816\nx3  -.552    .818\nx4   .846    .515\nx5   .855    .500\nx6   .844    .515\n\n── Variances Accounted for ─────────────────────────────────────────────────────\n\n                     F1      F2  \nSS loadings          3.093   2.781\nProp Tot Var         0.515   0.463\nCum Prop Tot Var     0.515   0.979\nProp Comm Var        0.527   0.473\nCum Prop Comm Var    0.527   1.000\n\n── Model Fit ───────────────────────────────────────────────────────────────────\n\n𝜒²(4) =  1.47, p = .832\nCFI = 1.00\nRMSEA [90% CI] = .00 [.00; .06]\nAIC = -6.53\nBIC = -20.61\nCAF = .50"
  },
  {
    "objectID": "posts/Exploratory Factor Analysis/index.html#rotating-solution",
    "href": "posts/Exploratory Factor Analysis/index.html#rotating-solution",
    "title": "Exploratory Factor Analysis",
    "section": "Rotating solution",
    "text": "Rotating solution\nEFAtools\n\n\nCode\nEFA(df, n_factors = 2, rotation = \"promax\")\n\n\n\nEFA performed with type = 'EFAtools', method = 'PAF', and rotation = 'promax'.\n\n── Rotated Loadings ────────────────────────────────────────────────────────────\n\n     F1      F2  \nx1  -.004    .989\nx2  -.003    .991\nx3   .006    .987\nx4   .991    .005\nx5   .989   -.012\nx6   .989    .007\n\n── Factor Intercorrelations ────────────────────────────────────────────────────\n\n     F1      F2  \nF1   1.000  -0.058\nF2  -0.058   1.000\n\n── Variances Accounted for ─────────────────────────────────────────────────────\n\n                     F1      F2  \nSS loadings          3.107   2.766\nProp Tot Var         0.518   0.461\nCum Prop Tot Var     0.518   0.979\nProp Comm Var        0.529   0.471\nCum Prop Comm Var    0.529   1.000\n\n── Model Fit ───────────────────────────────────────────────────────────────────\n\nCAF: .50\ndf:   4"
  },
  {
    "objectID": "posts/Exploratory Factor Analysis/index.html#factor-extraction-1",
    "href": "posts/Exploratory Factor Analysis/index.html#factor-extraction-1",
    "title": "Exploratory Factor Analysis",
    "section": "Factor Extraction",
    "text": "Factor Extraction\npsych\n\n\nCode\nFA_df&lt;- fa(df, nfactors=2, fm=\"ml\")\nsummary.psych(FA_df)\n\n\n\nFactor analysis with Call: fa(r = df, nfactors = 2, fm = \"ml\")\n\nTest of the hypothesis that 2 factors are sufficient.\nThe degrees of freedom for the model is 4  and the objective function was  0.01 \nThe number of observations was  250  with Chi Square =  1.45  with prob &lt;  0.84 \n\nThe root mean square of the residuals (RMSA) is  0 \nThe df corrected root mean square of the residuals is  0 \n\nTucker Lewis Index of factoring reliability =  1.003\nRMSEA index =  0  and the 10 % confidence intervals are  0 0.055\nBIC =  -20.64\n With factor correlations of \n      ML1   ML2\nML1  1.00 -0.06\nML2 -0.06  1.00"
  },
  {
    "objectID": "posts/Exploratory Factor Analysis/index.html#factor-extraction-psych-continued",
    "href": "posts/Exploratory Factor Analysis/index.html#factor-extraction-psych-continued",
    "title": "Exploratory Factor Analysis",
    "section": "Factor Extraction, psych continued",
    "text": "Factor Extraction, psych continued\nExamine the residuals\n\n\nCode\nresiduals.psych(FA_df)\n\n\n   x1   x2   x3   x4   x5   x6  \nx1 0.02                         \nx2 0.00 0.02                    \nx3 0.00 0.00 0.03               \nx4 0.00 0.00 0.00 0.02          \nx5 0.00 0.00 0.00 0.00 0.02     \nx6 0.00 0.00 0.00 0.00 0.00 0.02"
  },
  {
    "objectID": "posts/Exploratory Factor Analysis/index.html#interpretation-psych",
    "href": "posts/Exploratory Factor Analysis/index.html#interpretation-psych",
    "title": "Exploratory Factor Analysis",
    "section": "Interpretation, psych",
    "text": "Interpretation, psych\n\n\nCode\nFA_df$loadings\n\n\n\nLoadings:\n   ML1    ML2   \nx1         0.989\nx2         0.991\nx3         0.987\nx4  0.991       \nx5  0.989       \nx6  0.989       \n\n                 ML1   ML2\nSS loadings    2.939 2.935\nProportion Var 0.490 0.489\nCumulative Var 0.490 0.979"
  },
  {
    "objectID": "posts/Exploratory Factor Analysis/index.html#rotating-solution-2-oblimin",
    "href": "posts/Exploratory Factor Analysis/index.html#rotating-solution-2-oblimin",
    "title": "Exploratory Factor Analysis",
    "section": "Rotating solution 2, oblimin",
    "text": "Rotating solution 2, oblimin\nEFAtools\n\n\nCode\nEFA(df, n_factors = 2, rotation = \"oblimin\", method = \"ULS\")\n\n\n\nEFA performed with type = 'EFAtools', method = 'ULS', and rotation = 'oblimin'.\n\n── Rotated Loadings ────────────────────────────────────────────────────────────\n\n     F1      F2  \nx1  -.004    .989\nx2  -.003    .991\nx3   .006    .987\nx4   .991    .005\nx5   .989   -.012\nx6   .989    .007\n\n── Factor Intercorrelations ────────────────────────────────────────────────────\n\n     F1      F2  \nF1   1.000  -0.058\nF2  -0.058   1.000\n\n── Variances Accounted for ─────────────────────────────────────────────────────\n\n                     F1      F2  \nSS loadings          3.107   2.766\nProp Tot Var         0.518   0.461\nCum Prop Tot Var     0.518   0.979\nProp Comm Var        0.529   0.471\nCum Prop Comm Var    0.529   1.000\n\n── Model Fit ───────────────────────────────────────────────────────────────────\n\n𝜒²(4) =  0.00, p =1.000\nCFI = 1.00\nRMSEA [90% CI] = .00 [.00; .00]\nAIC = -8.00\nBIC = -22.09\nCAF = .50"
  },
  {
    "objectID": "posts/Exploratory Factor Analysis/index.html#mental-break-down",
    "href": "posts/Exploratory Factor Analysis/index.html#mental-break-down",
    "title": "Exploratory Factor Analysis",
    "section": "Mental Break (down)",
    "text": "Mental Break (down)\nProbably a lot to process in one go. We will take a mental break here and then we will work together through the next example."
  },
  {
    "objectID": "posts/Exploratory Factor Analysis/index.html#but-but-what-about-lavaan",
    "href": "posts/Exploratory Factor Analysis/index.html#but-but-what-about-lavaan",
    "title": "Exploratory Factor Analysis",
    "section": "But, but, what about lavaan???",
    "text": "But, but, what about lavaan???\nYes we have left lavaan out so far. Now is the time to have a look of how we could go through the above process using lavaan (partially).\n\n\nCode\nlibrary(lavaan)\n\nefa.model.fit &lt;- lavaan::efa(data = df, nfactors = 2, rotation = \"promax\")\nsummary(efa.model.fit)\n\n\nThis is lavaan 0.6.17 -- running exploratory factor analysis\n\n  Estimator                                         ML\n  Rotation method                       PROMAX OBLIQUE\n  Promax kappa                                       4\n  Rotation algorithm (rstarts)              PROMAX (0)\n  Standardized metric                             TRUE\n  Row weights                                   Kaiser\n\n  Number of observations                           250\n\nFit measures:\n                   aic      bic    sabic chisq df pvalue cfi rmsea\n  nfactors = 2 1025.02 1084.885 1030.994 1.478  4  0.831   1     0\n\nEigenvalues correlation matrix:\n\n     ev1      ev2      ev3      ev4      ev5      ev6 \n  3.1285   2.7871   0.0247   0.0214   0.0193   0.0189 \n\nStandardized loadings:\n\n       f1     f2      unique.var   communalities\nx1  0.989                  0.021           0.979\nx2  0.991                  0.018           0.982\nx3  0.987                  0.026           0.974\nx4         0.991           0.019           0.981\nx5         0.989           0.020           0.980\nx6         0.989           0.022           0.978\n\n                              f2    f1 total\nSum of sq (obliq) loadings 2.939 2.935 5.873\nProportion of total        0.500 0.500 1.000\nProportion var             0.490 0.489 0.979\nCumulative var             0.490 0.979 0.979\n\nFactor correlations:\n\n       f1     f2\nf1  1.000       \nf2 -0.058  1.000"
  },
  {
    "objectID": "posts/Exploratory Factor Analysis/index.html#ok-time-for-our-collaborative-example",
    "href": "posts/Exploratory Factor Analysis/index.html#ok-time-for-our-collaborative-example",
    "title": "Exploratory Factor Analysis",
    "section": "OK, time for our collaborative example",
    "text": "OK, time for our collaborative example\nWe will use a lavaan built-in dataset called HolzingerSwineford1939\nThe data consists of mental ability test scores of seventh- and eighth-grade children from two different schools (Pasteur and Grant-White). In our version of the dataset, only 9 out of the original 26 tests are included. A CFA model that is often proposed for these 9 variables consists of three latent variables (or factors), each with three indicators:\n\na visual factor measured by 3 variables: x1, x2 and x3\na textual factor measured by 3 variables: x4, x5 and x6\na speed factor measured by 3 variables: x7, x8 and x9"
  },
  {
    "objectID": "posts/Exploratory Factor Analysis/index.html#visual-model",
    "href": "posts/Exploratory Factor Analysis/index.html#visual-model",
    "title": "Exploratory Factor Analysis",
    "section": "Visual Model",
    "text": "Visual Model"
  },
  {
    "objectID": "posts/Exploratory Factor Analysis/index.html#let-us-assign-the-data-to-a-dataframe",
    "href": "posts/Exploratory Factor Analysis/index.html#let-us-assign-the-data-to-a-dataframe",
    "title": "Exploratory Factor Analysis",
    "section": "Let us assign the data to a dataframe",
    "text": "Let us assign the data to a dataframe\n\n\nCode\ndata(HolzingerSwineford1939)\ndf2 &lt;- HolzingerSwineford1939\nhead(df2)\n\n\n  id sex ageyr agemo  school grade       x1   x2    x3       x4   x5        x6\n1  1   1    13     1 Pasteur     7 3.333333 7.75 0.375 2.333333 5.75 1.2857143\n2  2   2    13     7 Pasteur     7 5.333333 5.25 2.125 1.666667 3.00 1.2857143\n3  3   2    13     1 Pasteur     7 4.500000 5.25 1.875 1.000000 1.75 0.4285714\n4  4   1    13     2 Pasteur     7 5.333333 7.75 3.000 2.666667 4.50 2.4285714\n5  5   2    12     2 Pasteur     7 4.833333 4.75 0.875 2.666667 4.00 2.5714286\n6  6   2    14     1 Pasteur     7 5.333333 5.00 2.250 1.000000 3.00 0.8571429\n        x7   x8       x9\n1 3.391304 5.75 6.361111\n2 3.782609 6.25 7.916667\n3 3.260870 3.90 4.416667\n4 3.000000 5.30 4.861111\n5 3.695652 6.30 5.916667\n6 4.347826 6.65 7.500000"
  },
  {
    "objectID": "posts/Exploratory Factor Analysis/index.html#keep-only-the-indicators-columns",
    "href": "posts/Exploratory Factor Analysis/index.html#keep-only-the-indicators-columns",
    "title": "Exploratory Factor Analysis",
    "section": "Keep only the indicators columns",
    "text": "Keep only the indicators columns\n\n\nCode\nlibrary(tidyverse)\ndf2 &lt;- df2 |&gt; \n  dplyr::select(7:15)"
  },
  {
    "objectID": "posts/Exploratory Factor Analysis/index.html#what-should-be-our-first-step",
    "href": "posts/Exploratory Factor Analysis/index.html#what-should-be-our-first-step",
    "title": "Exploratory Factor Analysis",
    "section": "What should be our first step?",
    "text": "What should be our first step?"
  },
  {
    "objectID": "posts/Confirmatory Factor Analysis/index.html#todays-aims",
    "href": "posts/Confirmatory Factor Analysis/index.html#todays-aims",
    "title": "Confirmatory Factor Analysis",
    "section": "Today’s Aims",
    "text": "Today’s Aims\nToday we will go through confirmatory factor analysis using lavaan. Our main focus will be lavaan syntax and the interpretation of output for different models and not going through the detailed mathematics behind the CFA processes. We will get a chance to talk about the mathematics and more during the next weeks of more intermediate and advanced topics."
  },
  {
    "objectID": "posts/Confirmatory Factor Analysis/index.html#todays-examples",
    "href": "posts/Confirmatory Factor Analysis/index.html#todays-examples",
    "title": "Confirmatory Factor Analysis",
    "section": "Today’s examples",
    "text": "Today’s examples\nWe will be working on the same variables that we generated last week during the EFA. We will go through the process of one factor CFA and two factor CFA.\nWe specifically explored a model with two factors and overall 6 items, today we will first attempt to confirm a model where three items load to latent variable A. This will be our one-factor CFA.\nIn the second part of our workshop we will attempt to confirm a model with two latent variables A and B."
  },
  {
    "objectID": "posts/Confirmatory Factor Analysis/index.html#terminology",
    "href": "posts/Confirmatory Factor Analysis/index.html#terminology",
    "title": "Confirmatory Factor Analysis",
    "section": "Terminology",
    "text": "Terminology\nToday we will also be referring back to many of the terms that we have defined in the past.\n\nObserved variables\nLatent variables\nDirectional/regression paths\nNon-directional paths/covariance/variance\nModel parameters\nExogenous, endogenous variables\nMeasurement and structural model"
  },
  {
    "objectID": "posts/Confirmatory Factor Analysis/index.html#we-will-expand-on-terminology-today",
    "href": "posts/Confirmatory Factor Analysis/index.html#we-will-expand-on-terminology-today",
    "title": "Confirmatory Factor Analysis",
    "section": "We will expand on terminology today",
    "text": "We will expand on terminology today\n\nScale: latent variables do not have a measurement scale, instead we have to define one for them. To do that we need to set an origin and a unit\n\nOrigin: we can set the mean to 0\nUnit\n\nEither set the variance to 1\nOr, use the same unit as that of one of the measured variables ( only 1 item)"
  },
  {
    "objectID": "posts/Confirmatory Factor Analysis/index.html#notations-in-lavaan-refresher",
    "href": "posts/Confirmatory Factor Analysis/index.html#notations-in-lavaan-refresher",
    "title": "Confirmatory Factor Analysis",
    "section": "Notations in lavaan (refresher)",
    "text": "Notations in lavaan (refresher)\n\n~ predict, used for regression of observed outcome to observed predictors\n=~ indicator, used for latent variable to observed indicators\n~~ covariance\n1* fixes parameter or loading to 1\nNA* frees parameter or loading\n~1 intercept or mean (e.g., x1 ~ 1 estimates the mean of variable x1)\na* defines the parameter ‘a’,"
  },
  {
    "objectID": "posts/Confirmatory Factor Analysis/index.html#number-of-parameters-refresher",
    "href": "posts/Confirmatory Factor Analysis/index.html#number-of-parameters-refresher",
    "title": "Confirmatory Factor Analysis",
    "section": "Number of parameters (refresher)",
    "text": "Number of parameters (refresher)\nAs mentioned before every path or (co)variance that has not been fixed to a specific value will have to be estimated\n\nFactor loadings\nFactor covariances\nFactor variances\nError variances"
  },
  {
    "objectID": "posts/Confirmatory Factor Analysis/index.html#last-weeks-example",
    "href": "posts/Confirmatory Factor Analysis/index.html#last-weeks-example",
    "title": "Confirmatory Factor Analysis",
    "section": "Last week’s example",
    "text": "Last week’s example\nLast week we generated random data using the 1212 seed. Today we will carry out CFA on the same model but using 3131 as a seed.\n\n\nCode\nset.seed(3131)\n### normally distributed factors\n### these are just to help me set the indicators\n### the f1 and f2 will not be included in the data.frame\nf1 &lt;- rnorm(250)\nf2 &lt;- rnorm(250)\n\n### f1 indicators x1 to x3\nx1 &lt;- f1 + rnorm(250, sd=0.15)\nx2 &lt;- f1 + rnorm(250, sd=0.15)\nx3 &lt;- f1 + rnorm(250, sd=0.15)\n\n### f2 indicators x4 to x6\nx4 &lt;- f2 + rnorm(250, sd=0.15)\nx5 &lt;- f2 + rnorm(250, sd=0.15)\nx6 &lt;- f2 + rnorm(250, sd=0.15)\n\n### creating the dataframe\ndf &lt;- data.frame(x1=x1, x2=x2, x3=x3, x4=x4, x5=x5, x6=x6)"
  },
  {
    "objectID": "posts/Confirmatory Factor Analysis/index.html#one-factor-cfa",
    "href": "posts/Confirmatory Factor Analysis/index.html#one-factor-cfa",
    "title": "Confirmatory Factor Analysis",
    "section": "One factor CFA",
    "text": "One factor CFA"
  },
  {
    "objectID": "posts/Confirmatory Factor Analysis/index.html#one-factor-cfa-expanded",
    "href": "posts/Confirmatory Factor Analysis/index.html#one-factor-cfa-expanded",
    "title": "Confirmatory Factor Analysis",
    "section": "One factor CFA, expanded",
    "text": "One factor CFA, expanded"
  },
  {
    "objectID": "posts/Confirmatory Factor Analysis/index.html#once-factor-cfa-expanded-again",
    "href": "posts/Confirmatory Factor Analysis/index.html#once-factor-cfa-expanded-again",
    "title": "Confirmatory Factor Analysis",
    "section": "Once factor CFA, expanded (again)",
    "text": "Once factor CFA, expanded (again)"
  },
  {
    "objectID": "posts/Confirmatory Factor Analysis/index.html#one-factor-cfa-and-degrees-of-freedom",
    "href": "posts/Confirmatory Factor Analysis/index.html#one-factor-cfa-and-degrees-of-freedom",
    "title": "Confirmatory Factor Analysis",
    "section": "One Factor CFA and degrees of freedom",
    "text": "One Factor CFA and degrees of freedom\n\ndf &lt; 0, the model is under-identified\ndf = 0, the model is just-identified (also known as saturated), no model fit\ndf &gt; 0, over-identified, we can assess model fit\n\nReminder: df = number of known values - number of parameters to estimate"
  },
  {
    "objectID": "posts/Confirmatory Factor Analysis/index.html#one-factor-cfa-and-degrees-of-freedom-1",
    "href": "posts/Confirmatory Factor Analysis/index.html#one-factor-cfa-and-degrees-of-freedom-1",
    "title": "Confirmatory Factor Analysis",
    "section": "One Factor CFA and degrees of freedom",
    "text": "One Factor CFA and degrees of freedom\n\nTotal number of parameters (alson knows as “known values”) as previously discussed\n\\[\np(p+1)/2\n\\] \\[\n3(4)/2=6\n\\]\nNumber of parameters to estimate???? (Let us revisit the slide with the model visualisation)"
  },
  {
    "objectID": "posts/Confirmatory Factor Analysis/index.html#identification-methods",
    "href": "posts/Confirmatory Factor Analysis/index.html#identification-methods",
    "title": "Confirmatory Factor Analysis",
    "section": "Identification Methods",
    "text": "Identification Methods\n\nmarker method: we fix the first loading of each factor to 1 (what does this mean?)\nvariance standardization method: we fix the variance of each factor to 1 and we freely estimate all other loadings (what does this mean?)\nstandardization all method, standardizes the variance of each factor to 1 but also standardizes the items\n\nNote: default lavaan method is the marker method"
  },
  {
    "objectID": "posts/Confirmatory Factor Analysis/index.html#let-us-see-this-example-in-lavaan",
    "href": "posts/Confirmatory Factor Analysis/index.html#let-us-see-this-example-in-lavaan",
    "title": "Confirmatory Factor Analysis",
    "section": "Let us see this example in lavaan",
    "text": "Let us see this example in lavaan\n\n\nCode\nlibrary(lavaan)\n\nmodel1 &lt;- '\nf1 =~ x1 + x2 + x3\n'\n\nmodel1.fit &lt;- cfa(model1, data = df)\n\nsummary(model1.fit)\n\n\nlavaan 0.6.17 ended normally after 51 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         6\n\n  Number of observations                           250\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  f1 =~                                               \n    x1                1.000                           \n    x2                0.992    0.014   72.880    0.000\n    x3                0.991    0.014   72.206    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .x1                0.019    0.003    6.471    0.000\n   .x2                0.023    0.003    7.277    0.000\n   .x3                0.023    0.003    7.424    0.000\n    f1                0.912    0.083   10.951    0.000"
  },
  {
    "objectID": "posts/Confirmatory Factor Analysis/index.html#how-can-we-interpret-this-output",
    "href": "posts/Confirmatory Factor Analysis/index.html#how-can-we-interpret-this-output",
    "title": "Confirmatory Factor Analysis",
    "section": "How can we interpret this output?",
    "text": "How can we interpret this output?\n\nx1 estimate is 1.000 and has no std error, z-value, nor p-value. This is because lavaan uses the marker method by default. x1 has been fixed to 1 and is now the scale of our factor 1.\nx2 estimate is 0.992. For an increase of 1 unit in f1, x2 increases by 0.992. The 1 unit in f1 is the unit of x1 as this was set to be the scale\n.x1 refers to residual variances, hence the . in front of x1\nf estimate of 0.912 is the variance of our latent variable (factor)\np-values are just telling us if our estimates are significantly greater than zero\n\nBut what about intercept???"
  },
  {
    "objectID": "posts/Confirmatory Factor Analysis/index.html#adding-intercept-in-lavaan",
    "href": "posts/Confirmatory Factor Analysis/index.html#adding-intercept-in-lavaan",
    "title": "Confirmatory Factor Analysis",
    "section": "Adding intercept in lavaan",
    "text": "Adding intercept in lavaan\n\n\nCode\nlibrary(lavaan)\n\nmodel1.inter &lt;- '\nf1 =~ x1 + x2 + x3\nf1 ~ 1 \n'\n\nmodel1.inter.fit &lt;- cfa(model1.inter, data = df)\n\nsummary(model1.inter.fit)\n\n\nlavaan 0.6.17 ended normally after 51 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        10\n\n  Number of observations                           250\n\nModel Test User Model:\n                                                      \n  Test statistic                                    NA\n  Degrees of freedom                                -1\n  P-value (Unknown)                                 NA\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  f1 =~                                               \n    x1                1.000                           \n    x2                0.992       NA                  \n    x3                0.991       NA                  \n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n    f1                0.000       NA                  \n   .x1                0.009       NA                  \n   .x2                0.036       NA                  \n   .x3                0.014       NA                  \n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .x1                0.019       NA                  \n   .x2                0.023       NA                  \n   .x3                0.023       NA                  \n    f1                0.912       NA"
  },
  {
    "objectID": "posts/Confirmatory Factor Analysis/index.html#what-about-variance-standardization-method",
    "href": "posts/Confirmatory Factor Analysis/index.html#what-about-variance-standardization-method",
    "title": "Confirmatory Factor Analysis",
    "section": "What about variance standardization method",
    "text": "What about variance standardization method\n\n\nCode\nlibrary(lavaan)\n\nmodel1.var &lt;- '\nf1 =~ NA*x1 + x2 + x3\nf1 ~~ 1*f1 \n'\n\nmodel1.var.fit &lt;- cfa(model1.var, data = df)\n\nsummary(model1.var.fit)\n\n\nlavaan 0.6.17 ended normally after 31 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         6\n\n  Number of observations                           250\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  f1 =~                                               \n    x1                0.955    0.044   21.901    0.000\n    x2                0.948    0.043   21.811    0.000\n    x3                0.946    0.043   21.792    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n    f1                1.000                           \n   .x1                0.019    0.003    6.471    0.000\n   .x2                0.023    0.003    7.277    0.000\n   .x3                0.023    0.003    7.424    0.000"
  },
  {
    "objectID": "posts/Confirmatory Factor Analysis/index.html#thanks-for-nothing-laz",
    "href": "posts/Confirmatory Factor Analysis/index.html#thanks-for-nothing-laz",
    "title": "Confirmatory Factor Analysis",
    "section": "Thanks for nothing Laz!",
    "text": "Thanks for nothing Laz!\n\n\nCode\nmodel1 &lt;- '\nf1 =~ x1 + x2 + x3\n'\n\nmodel1.fit &lt;- cfa(model1, std.lv=TRUE, data = df)\n\nsummary(model1.fit)\n\n\nlavaan 0.6.17 ended normally after 31 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         6\n\n  Number of observations                           250\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n  f1 =~                                               \n    x1                0.955    0.044   21.901    0.000\n    x2                0.948    0.043   21.811    0.000\n    x3                0.946    0.043   21.792    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)\n   .x1                0.019    0.003    6.471    0.000\n   .x2                0.023    0.003    7.277    0.000\n   .x3                0.023    0.003    7.424    0.000\n    f1                1.000"
  },
  {
    "objectID": "posts/Confirmatory Factor Analysis/index.html#interpretation",
    "href": "posts/Confirmatory Factor Analysis/index.html#interpretation",
    "title": "Confirmatory Factor Analysis",
    "section": "Interpretation",
    "text": "Interpretation\nRemember this method standardizes our factor, so we will need to speak in terms of standard deviations\nx1 estimate of 0.955: For an increase of 1 standard deviation in f1, x1 increases by 0.955"
  },
  {
    "objectID": "posts/Confirmatory Factor Analysis/index.html#and-the-magnificent-standardization-all-walks-in",
    "href": "posts/Confirmatory Factor Analysis/index.html#and-the-magnificent-standardization-all-walks-in",
    "title": "Confirmatory Factor Analysis",
    "section": "And the magnificent standardization all walks in",
    "text": "And the magnificent standardization all walks in\n\n\nCode\nmodel1 &lt;- '\nf1 =~ x1 + x2 + x3\n'\n\nmodel1.fit &lt;- cfa(model1, data = df)\n\nsummary(model1.fit, standardized=TRUE)\n\n\nlavaan 0.6.17 ended normally after 51 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         6\n\n  Number of observations                           250\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  f1 =~                                                                 \n    x1                1.000                               0.955    0.990\n    x2                0.992    0.014   72.880    0.000    0.948    0.988\n    x3                0.991    0.014   72.206    0.000    0.946    0.987\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .x1                0.019    0.003    6.471    0.000    0.019    0.020\n   .x2                0.023    0.003    7.277    0.000    0.023    0.024\n   .x3                0.023    0.003    7.424    0.000    0.023    0.025\n    f1                0.912    0.083   10.951    0.000    1.000    1.000"
  },
  {
    "objectID": "posts/Confirmatory Factor Analysis/index.html#moving-on-to-model-fit-statistics",
    "href": "posts/Confirmatory Factor Analysis/index.html#moving-on-to-model-fit-statistics",
    "title": "Confirmatory Factor Analysis",
    "section": "Moving on to Model fit statistics",
    "text": "Moving on to Model fit statistics\nAs things are now we cannot obtain model fit statistics as df =0\nSo our model is just-identified (saturated)\n\n\nCode\nmodel2 &lt;- '\nf1 =~ x1 + x2 + x3 + x4\nf2 =~ x5 + x6\n'\n\nmodel2.fit &lt;- cfa(model2, data = df)\nsummary(model2.fit, standardized=TRUE, fit.measures=TRUE)\n\n\nlavaan 0.6.17 ended normally after 48 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        13\n\n  Number of observations                           250\n\nModel Test User Model:\n                                                      \n  Test statistic                               812.060\n  Degrees of freedom                                 8\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                              3202.055\n  Degrees of freedom                                15\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.748\n  Tucker-Lewis Index (TLI)                       0.527\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)               -889.645\n  Loglikelihood unrestricted model (H1)       -483.616\n                                                      \n  Akaike (AIC)                                1805.291\n  Bayesian (BIC)                              1851.070\n  Sample-size adjusted Bayesian (SABIC)       1809.859\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.634\n  90 Percent confidence interval - lower         0.598\n  90 Percent confidence interval - upper         0.671\n  P-value H_0: RMSEA &lt;= 0.050                    0.000\n  P-value H_0: RMSEA &gt;= 0.080                    1.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.299\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  f1 =~                                                                 \n    x1                1.000                               0.955    0.990\n    x2                0.992    0.014   72.869    0.000    0.948    0.988\n    x3                0.991    0.014   72.277    0.000    0.946    0.987\n    x4               -0.090    0.065   -1.397    0.162   -0.086   -0.088\n  f2 =~                                                                 \n    x5                1.000                               0.960    0.961\n    x6                1.028    0.185    5.548    0.000    0.986    1.017\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  f1 ~~                                                                 \n    f2               -0.072    0.061   -1.180    0.238   -0.078   -0.078\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .x1                0.019    0.003    6.451    0.000    0.019    0.020\n   .x2                0.023    0.003    7.296    0.000    0.023    0.025\n   .x3                0.023    0.003    7.424    0.000    0.023    0.025\n   .x4                0.947    0.085   11.180    0.000    0.947    0.992\n   .x5                0.076    0.166    0.456    0.648    0.076    0.076\n   .x6               -0.032    0.175   -0.183    0.855   -0.032   -0.034\n    f1                0.912    0.083   10.952    0.000    1.000    1.000\n    f2                0.921    0.188    4.903    0.000    1.000    1.000"
  },
  {
    "objectID": "posts/Confirmatory Factor Analysis/index.html#what-if-we-make-sure-there-is-no-covariance-between-factors",
    "href": "posts/Confirmatory Factor Analysis/index.html#what-if-we-make-sure-there-is-no-covariance-between-factors",
    "title": "Confirmatory Factor Analysis",
    "section": "What if we make sure there is no covariance between factors?",
    "text": "What if we make sure there is no covariance between factors?\n\n\nCode\nmodel2.nocov &lt;- '\nf1 =~ x1 + x2 + x3 + x4\nf2 =~ x5 + x6\nf1~~0*f2\n'\n\nmodel2.nocov.fit &lt;- cfa(model2.nocov, data = df)\nsummary(model2.nocov.fit, standardized=TRUE, fit.measures=TRUE)\n\n\nlavaan 0.6.17 ended normally after 52 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        12\n\n  Number of observations                           250\n\nModel Test User Model:\n                                                      \n  Test statistic                               813.666\n  Degrees of freedom                                 9\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                              3202.055\n  Degrees of freedom                                15\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.748\n  Tucker-Lewis Index (TLI)                       0.579\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)               -890.449\n  Loglikelihood unrestricted model (H1)       -483.616\n                                                      \n  Akaike (AIC)                                1804.898\n  Bayesian (BIC)                              1847.155\n  Sample-size adjusted Bayesian (SABIC)       1809.114\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.598\n  90 Percent confidence interval - lower         0.564\n  90 Percent confidence interval - upper         0.633\n  P-value H_0: RMSEA &lt;= 0.050                    0.000\n  P-value H_0: RMSEA &gt;= 0.080                    1.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.303\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  f1 =~                                                                 \n    x1                1.000                               0.955    0.990\n    x2                0.992       NA                      0.948    0.988\n    x3                0.991       NA                      0.946    0.987\n    x4               -0.090       NA                     -0.086   -0.088\n  f2 =~                                                                 \n    x5                1.000                               0.921    0.922\n    x6                1.116       NA                      1.028    1.060\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  f1 ~~                                                                 \n    f2                0.000                               0.000    0.000\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .x1                0.019       NA                      0.019    0.020\n   .x2                0.023       NA                      0.023    0.025\n   .x3                0.023       NA                      0.023    0.025\n   .x4                0.948       NA                      0.948    0.992\n   .x5                0.149       NA                      0.149    0.149\n   .x6               -0.116       NA                     -0.116   -0.123\n    f1                0.912       NA                      1.000    1.000\n    f2                0.848       NA                      1.000    1.000"
  },
  {
    "objectID": "posts/Confirmatory Factor Analysis/index.html#can-we-improve-our-model",
    "href": "posts/Confirmatory Factor Analysis/index.html#can-we-improve-our-model",
    "title": "Confirmatory Factor Analysis",
    "section": "Can we improve our model?",
    "text": "Can we improve our model?\nOne way to do that is to look into our model residuals. Model residuals are an absolute fit index where we compare our model with th observed data. Generally, you regard absolute goodness of fit as the “discrepancy” between our model and the observed data. Higher residuals indicate greater discrepancy.\nSo how high is bad? We can request either correlations or standardized residuals."
  },
  {
    "objectID": "posts/Confirmatory Factor Analysis/index.html#correlations",
    "href": "posts/Confirmatory Factor Analysis/index.html#correlations",
    "title": "Confirmatory Factor Analysis",
    "section": "Correlations",
    "text": "Correlations\nHere both observed and estimated covariances are converted into correlations and then we calculate the differences. Greater differences indicate problematic items.\n\n\nCode\nresiduals(model2.fit, type=\"cor\")\n\n\n$type\n[1] \"cor.bollen\"\n\n$cov\n       x1     x2     x3     x4     x5     x6\nx1  0.000                                   \nx2  0.000  0.000                            \nx3  0.000  0.000  0.000                     \nx4 -0.010  0.013  0.001  0.000              \nx5 -0.010  0.015  0.000  0.967  0.000       \nx6 -0.010  0.015 -0.002  0.968  0.000  0.000"
  },
  {
    "objectID": "posts/Confirmatory Factor Analysis/index.html#standardized-residuals",
    "href": "posts/Confirmatory Factor Analysis/index.html#standardized-residuals",
    "title": "Confirmatory Factor Analysis",
    "section": "Standardized residuals",
    "text": "Standardized residuals\nHere we standardize the covariance and in practice treat it as a z-score, values greater than 1.96 indicate problematic cases.\n\n\nCode\nresiduals(model2.fit, type=\"standardized\")\n\n\n$type\n[1] \"standardized\"\n\n$cov\n       x1     x2     x3     x4     x5     x6\nx1  0.000                                   \nx2  0.000  0.000                            \nx3 -1.636  1.394  0.000                     \nx4 -1.342  1.533  0.108  0.000              \nx5 -1.462  1.783  0.010 11.027  0.000       \nx6 -1.347  1.868 -0.199 11.039  0.000  0.000"
  },
  {
    "objectID": "posts/Confirmatory Factor Analysis/index.html#modification-indices",
    "href": "posts/Confirmatory Factor Analysis/index.html#modification-indices",
    "title": "Confirmatory Factor Analysis",
    "section": "Modification Indices",
    "text": "Modification Indices\nWe should look at modification indices that give as an estimate change of our chi-square value if we make changes to our model.\n\n\nCode\nmodificationindices(model2.fit)\n\n\n   lhs op rhs      mi    epc sepc.lv sepc.all sepc.nox\n18  f2 =~  x1   1.522 -0.014  -0.013   -0.014   -0.014\n19  f2 =~  x2   3.561  0.022   0.021    0.022    0.022\n20  f2 =~  x3   0.117 -0.004  -0.004   -0.004   -0.004\n21  f2 =~  x4 225.561  0.939   0.901    0.923    0.923\n22  x1 ~~  x2   0.105  0.030   0.030    1.446    1.446\n23  x1 ~~  x3   5.001 -0.204  -0.204   -9.753   -9.753\n24  x1 ~~  x4   1.821 -0.015  -0.015   -0.109   -0.109\n25  x1 ~~  x5   0.481 -0.002  -0.002   -0.043   -0.043\n26  x1 ~~  x6   0.153  0.001   0.001    0.036    0.036\n27  x2 ~~  x3   3.971  0.173   0.173    7.516    7.516\n28  x2 ~~  x4   2.366  0.017   0.017    0.117    0.117\n29  x2 ~~  x5   0.042  0.000   0.000   -0.012   -0.012\n30  x2 ~~  x6   0.357  0.001   0.001    0.052    0.052\n31  x3 ~~  x4   0.012  0.001   0.001    0.008    0.008\n32  x3 ~~  x5   0.931  0.002   0.002    0.056    0.056\n33  x3 ~~  x6   0.970 -0.002  -0.002   -0.085   -0.085\n34  x4 ~~  x5   2.227  0.019   0.019    0.072    0.072\n35  x4 ~~  x6   3.243  0.023   0.023    0.130    0.130"
  },
  {
    "objectID": "posts/Confirmatory Factor Analysis/index.html#modifying-the-model",
    "href": "posts/Confirmatory Factor Analysis/index.html#modifying-the-model",
    "title": "Confirmatory Factor Analysis",
    "section": "Modifying the model",
    "text": "Modifying the model\n\n\nCode\nmodel2.1 &lt;- '\nf1 =~ x1 + x2 + x3 \nf2 =~ x4 + x5 + x6\n'\n\nmodel2.1.fit &lt;- cfa(model2.1, data = df)\nsummary(model2.1.fit, standardized=TRUE, fit.measures=TRUE)\n\n\nlavaan 0.6.17 ended normally after 58 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        13\n\n  Number of observations                           250\n\nModel Test User Model:\n                                                      \n  Test statistic                                 7.569\n  Degrees of freedom                                 8\n  P-value (Chi-square)                           0.477\n\nModel Test Baseline Model:\n\n  Test statistic                              3202.055\n  Degrees of freedom                                15\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    1.000\n  Tucker-Lewis Index (TLI)                       1.000\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)               -487.400\n  Loglikelihood unrestricted model (H1)       -483.616\n                                                      \n  Akaike (AIC)                                1000.800\n  Bayesian (BIC)                              1046.579\n  Sample-size adjusted Bayesian (SABIC)       1005.368\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.000\n  90 Percent confidence interval - lower         0.000\n  90 Percent confidence interval - upper         0.072\n  P-value H_0: RMSEA &lt;= 0.050                    0.817\n  P-value H_0: RMSEA &gt;= 0.080                    0.025\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.007\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  f1 =~                                                                 \n    x1                1.000                               0.955    0.990\n    x2                0.992    0.014   72.877    0.000    0.948    0.988\n    x3                0.991    0.014   72.242    0.000    0.946    0.987\n  f2 =~                                                                 \n    x4                1.000                               0.963    0.986\n    x5                1.024    0.015   66.812    0.000    0.986    0.988\n    x6                0.997    0.014   69.570    0.000    0.960    0.990\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  f1 ~~                                                                 \n    f2               -0.074    0.059   -1.263    0.206   -0.081   -0.081\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .x1                0.019    0.003    6.461    0.000    0.019    0.020\n   .x2                0.023    0.003    7.286    0.000    0.023    0.025\n   .x3                0.023    0.003    7.424    0.000    0.023    0.025\n   .x4                0.027    0.004    7.763    0.000    0.027    0.029\n   .x5                0.025    0.003    7.099    0.000    0.025    0.025\n   .x6                0.019    0.003    6.260    0.000    0.019    0.020\n    f1                0.912    0.083   10.951    0.000    1.000    1.000\n    f2                0.927    0.085   10.858    0.000    1.000    1.000"
  },
  {
    "objectID": "posts/Confirmatory Factor Analysis/index.html#let-us-see-if-the-residuals-tell-the-same-story",
    "href": "posts/Confirmatory Factor Analysis/index.html#let-us-see-if-the-residuals-tell-the-same-story",
    "title": "Confirmatory Factor Analysis",
    "section": "Let us see if the residuals tell the same story",
    "text": "Let us see if the residuals tell the same story\n\n\nCode\nresiduals(model2.1.fit, type=\"standardized\")\n\n\n$type\n[1] \"standardized\"\n\n$cov\n       x1     x2     x3     x4     x5     x6\nx1  0.000                                   \nx2  0.000  0.000                            \nx3 -1.669  1.497  0.000                     \nx4 -1.576  0.327 -0.624  0.000              \nx5 -0.533  1.678  0.406  0.000  0.000       \nx6 -0.907  1.477 -0.104 -0.684  0.861  0.000"
  },
  {
    "objectID": "posts/Confirmatory Factor Analysis/index.html#what-about-modification-indices",
    "href": "posts/Confirmatory Factor Analysis/index.html#what-about-modification-indices",
    "title": "Confirmatory Factor Analysis",
    "section": "What about modification indices",
    "text": "What about modification indices\n\n\nCode\nmodificationindices(model2.1.fit)\n\n\n   lhs op rhs    mi    epc sepc.lv sepc.all sepc.nox\n16  f1 =~  x4 0.787 -0.012  -0.011   -0.011   -0.011\n17  f1 =~  x5 0.439  0.008   0.008    0.008    0.008\n18  f1 =~  x6 0.031  0.002   0.002    0.002    0.002\n19  f2 =~  x1 2.236 -0.017  -0.017   -0.017   -0.017\n20  f2 =~  x2 2.856  0.020   0.020    0.020    0.020\n21  f2 =~  x3 0.016 -0.002  -0.001   -0.002   -0.002\n22  x1 ~~  x2 0.016  0.017   0.017    0.839    0.839\n23  x1 ~~  x3 2.856 -0.229  -0.229  -10.923  -10.923\n24  x1 ~~  x4 0.031  0.000   0.000    0.016    0.016\n25  x1 ~~  x5 0.476 -0.001  -0.001   -0.067   -0.067\n26  x1 ~~  x6 0.051  0.000   0.000    0.023    0.023\n27  x2 ~~  x3 2.236  0.192   0.192    8.386    8.386\n28  x2 ~~  x4 1.923 -0.003  -0.003   -0.124   -0.124\n29  x2 ~~  x5 0.174  0.001   0.001    0.039    0.039\n30  x2 ~~  x6 1.393  0.002   0.002    0.116    0.116\n31  x3 ~~  x4 1.090  0.002   0.002    0.093    0.093\n32  x3 ~~  x5 0.189  0.001   0.001    0.040    0.040\n33  x3 ~~  x6 1.946 -0.003  -0.003   -0.136   -0.136\n34  x4 ~~  x5 0.031 -0.024  -0.024   -0.941   -0.941\n35  x4 ~~  x6 0.439 -0.093  -0.093   -4.050   -4.050\n36  x5 ~~  x6 0.787  0.133   0.133    6.150    6.150"
  },
  {
    "objectID": "posts/Confirmatory Factor Analysis/index.html#exercise",
    "href": "posts/Confirmatory Factor Analysis/index.html#exercise",
    "title": "Confirmatory Factor Analysis",
    "section": "Exercise",
    "text": "Exercise\nLet us try a different model now. Go onto your posit cloud account and open the Week 5 project, follow the instructions and carry out the required CFA."
  }
]